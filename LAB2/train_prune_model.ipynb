{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3at1mhslz9v"
   },
   "source": [
    "## 掛載雲端硬碟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijtFdN9tl14V"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5bhyRZrl4X2"
   },
   "source": [
    "## 更改檔案所在路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2RXiD5Bl6a2"
   },
   "outputs": [],
   "source": [
    "# # Change to your own folder !!!\n",
    "# %cd /content/drive/MyDrive/your own folder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSal5HL0lTHA"
   },
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6v2iM_kglWj-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models.resnet import ResNet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFgiQGL6mq6W"
   },
   "source": [
    "## 設定超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8FQ-IsUmqtP"
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "TRAIN_BATCH_SIZE = 100\n",
    "TEST_BATCH_SIZE = 1000\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "LOG_INTERVAL = 100\n",
    "CUDA = True\n",
    "\n",
    "RESUME = True\n",
    "START_EPOCH = 0\n",
    "\n",
    "PRUNE_PATH = './model_prune.pth' # Change to your own folder !!!\n",
    "PRUNE_FINETUNE_PATH = './model_prune_finetune.pth' # Change to your own folder !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yk2vUEvtE8H3"
   },
   "source": [
    "#### 檢查是否檢查是否可使用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Sa1Tmnym3Pn"
   },
   "outputs": [],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    CUDA = True\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "else:\n",
    "    CUDA = False\n",
    "    kwargs = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fylf4FTlm7QX"
   },
   "source": [
    "## 下載資料集\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erS9S_76nUsG"
   },
   "source": [
    "這裡將訓練集做Augmentation(Pad, RandCrop, Random)，測試集不用做Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBW21uIHm_C-"
   },
   "outputs": [],
   "source": [
    "#### DATASET ####\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Pad(4),\n",
    "                       transforms.RandomCrop(32),\n",
    "                       transforms.RandomHorizontalFlip(),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                   ])),\n",
    "    batch_size=TRAIN_BATCH_SIZE, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                   ])),\n",
    "    batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is49FKBbuRj2"
   },
   "source": [
    "## 載入剪枝後的網路與權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUbUcHN4uQ89"
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "if(RESUME):\n",
    "  checkpoint = torch.load(PRUNE_PATH)\n",
    "  cfg = checkpoint['cfg']\n",
    "  model = ResNet50(num_classes=10,cfg=cfg)\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "  print('RESUME PRUNE MODEL')\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_MA9uRDx1tF"
   },
   "source": [
    "## 設定 Optimizer & CrossEntropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFi0J1-Ux1br"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gR2UTh0iwbEF"
   },
   "source": [
    "## 定義訓練跟測試函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQcKuMDee46V"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#### 訓練函數 #####\n",
    "\n",
    "# 注意: 需自行撰寫儲存每個epoch之train acc的code，以便後續繪製train acc結果圖!\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for data, target in tqdm(train_loader):\n",
    "        if CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "        # save training loss & acc \n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        train_correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        train_total += target.size(0)\n",
    "\n",
    "        # if batch_idx % LOG_INTERVAL == 0:\n",
    "        #     print('\\nTrain Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        #         100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "#### 測試函數 ####\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            if CUDA:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            test_total += target.size(0)\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "          test_loss, correct, len(test_loader.dataset),\n",
    "          100. * correct / len(test_loader.dataset)))\n",
    "      \n",
    "        test_acc = 100 * correct / test_total\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        return correct / float(len(test_loader.dataset))\n",
    "\n",
    "\n",
    "best_prec1 = 0.\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    # Learning Rate在0.5EPOCHS與0.75EPOCHS調整為原本之十分之一\n",
    "    if epoch in [EPOCHS*0.5, EPOCHS*0.75]:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1\n",
    "    train(epoch)\n",
    "    prec1 = test()\n",
    "\n",
    "    # 儲存模型權重\n",
    "    if(prec1 > best_prec1):\n",
    "        best_prec1 = prec1\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'cfg': cfg\n",
    "        }, PRUNE_FINETUNE_PATH)\n",
    "\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "\n",
    "print('\\n TRAIN PRUNED MODEL DONE!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8I1zyyqmNtQk"
   },
   "source": [
    "## 繪製Fine-tuning結果圖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WH1VaayxN1Qj"
   },
   "outputs": [],
   "source": [
    "#繪製Fine-tuning結果圖\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_acc_all():\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title('All acc')\n",
    "\n",
    "    ax1.plot(train_accuracies)\n",
    "    ax1.plot(test_accuracies)\n",
    "\n",
    "    ax1.legend(['train_acc', 'test_acc'], loc='upper left')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "def plt_loss_all():\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title('All loss')\n",
    "\n",
    "    ax1.plot(train_losses)\n",
    "    ax1.plot(test_losses)\n",
    "\n",
    "    ax1.legend(['train_loss', 'test_loss'], loc='upper left')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt_loss_all()\n",
    "plt_acc_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YBefoSG12TQ"
   },
   "source": [
    "## FLOPs & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6Ufr2LI1zzn"
   },
   "outputs": [],
   "source": [
    "!pip install thop\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0aEi9Al1-Yr"
   },
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "from torchsummary import summary\n",
    "\n",
    "##### 使用 thop 計算 FLOPs 和參數數量 #####\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "flops, params = profile(model, inputs=(dummy_input, ))\n",
    "\n",
    "print(f\"FLOPs: {flops}\")\n",
    "print(f\"Params: {params}\")\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EAI_Lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
