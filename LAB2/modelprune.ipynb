{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk6d9yOhuSkr"
   },
   "source": [
    "## 掛載雲端硬碟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3NTpFfZGuVSx"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEETyGg0uZnb"
   },
   "source": [
    "## 更改檔案所在路徑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Wum2GQmwucfZ"
   },
   "outputs": [],
   "source": [
    "# # Change to your own folder !!!\n",
    "# %cd /content/drive/MyDrive/your own folder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9NTZ1VEtbV7"
   },
   "source": [
    "## 載入函式庫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vCvF-fM0tfsq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from models.resnet import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X_r4dtMuwbh"
   },
   "source": [
    "## 超參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_2NkY0LyuyQh"
   },
   "outputs": [],
   "source": [
    "DATASET = 'cifar10'\n",
    "TEST_BATCH_SIZE = 1000\n",
    "CUDA = True\n",
    "PRUNE_PERCENT = 0.9 # Change your prune ratio!\n",
    "WEIGHT_PATH = './model_best.pth' # Change to your own folder !!!\n",
    "PRUNE_PATH = './model_prune.pth' # Change to your own folder !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7z4dkhJwB4Z"
   },
   "source": [
    "## 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lpIqnhfKwEcJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING CHECKPOINT ./model_best.pth @EPOCH=34, BEST_PREC1=0.9039999842643738\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "\n",
    "model = ResNet50(num_classes=10)\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "if WEIGHT_PATH:\n",
    "    if os.path.isfile(WEIGHT_PATH):\n",
    "        checkpoint = torch.load(WEIGHT_PATH)\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print('LOADING CHECKPOINT {} @EPOCH={}, BEST_PREC1={}'.format(WEIGHT_PATH,checkpoint['epoch'],best_prec1))\n",
    "\n",
    "    else:\n",
    "        print(\"NO CHECKPOINT FOUND\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srauYOD-1vSp"
   },
   "source": [
    "## 進行剪枝\n",
    "#### 計算所有Batch Normalizaiton中的scale factor絕對值大小並排序\n",
    "#### 利用設定好的PRUNE_PERCENT來取得閥值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xgtUBaDw1uuR"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        total += m.weight.data.shape[0]\n",
    "\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        size = m.weight.data.shape[0]\n",
    "        bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "        index += size\n",
    "\n",
    "y, i = torch.sort(bn)\n",
    "\n",
    "threshold_index = int(total * PRUNE_PERCENT)\n",
    "threshold = y[threshold_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66vDWd5BMmph"
   },
   "source": [
    "## 根據Batch Normalization Layer資訊建立CONFIG\n",
    "#### 1. 複製Batch Normalization Layer的weight(也就是scale factor γ)\n",
    "#### 2. 建立mask，大於threshold的index的值會設成1,小於threshold的值會設成0\n",
    "#### 3. mask的值加總後，會是剪枝後Layer對應的輸出channel數\n",
    "#### 4. 最後得到要建立剪枝模型的CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PBklaqUZHnvp"
   },
   "outputs": [],
   "source": [
    "pruned = 0\n",
    "cfg = []  #用來建立剪枝網路的CONFIG\n",
    "cfg_mask = [] #用來幫助剪枝的遮罩\n",
    "cfg_origin = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "10ilGgoZ1SR1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer index: 2 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 8 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 10 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 12 \t total channel: 256 \t remaining channel: 255\n",
      "layer index: 18 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 20 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 22 \t total channel: 256 \t remaining channel: 218\n",
      "layer index: 26 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 28 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 30 \t total channel: 256 \t remaining channel: 94\n",
      "layer index: 35 \t total channel: 128 \t remaining channel: 117\n",
      "layer index: 37 \t total channel: 128 \t remaining channel: 108\n",
      "layer index: 39 \t total channel: 512 \t remaining channel: 150\n",
      "layer index: 45 \t total channel: 128 \t remaining channel: 78\n",
      "layer index: 47 \t total channel: 128 \t remaining channel: 117\n",
      "layer index: 49 \t total channel: 512 \t remaining channel: 84\n",
      "layer index: 53 \t total channel: 128 \t remaining channel: 73\n",
      "layer index: 55 \t total channel: 128 \t remaining channel: 87\n",
      "layer index: 57 \t total channel: 512 \t remaining channel: 43\n",
      "layer index: 61 \t total channel: 128 \t remaining channel: 54\n",
      "layer index: 63 \t total channel: 128 \t remaining channel: 59\n",
      "layer index: 65 \t total channel: 512 \t remaining channel: 15\n",
      "layer index: 70 \t total channel: 256 \t remaining channel: 13\n",
      "layer index: 72 \t total channel: 256 \t remaining channel: 9\n",
      "layer index: 74 \t total channel: 1024 \t remaining channel: 70\n",
      "layer index: 80 \t total channel: 256 \t remaining channel: 6\n",
      "layer index: 82 \t total channel: 256 \t remaining channel: 10\n",
      "layer index: 84 \t total channel: 1024 \t remaining channel: 26\n",
      "Warning: layer 88 all channels pruned, keeping top 3...\n",
      "layer index: 88 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 90 \t total channel: 256 \t remaining channel: 5\n",
      "layer index: 92 \t total channel: 1024 \t remaining channel: 10\n",
      "Warning: layer 96 all channels pruned, keeping top 3...\n",
      "layer index: 96 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 98 all channels pruned, keeping top 3...\n",
      "layer index: 98 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 100 all channels pruned, keeping top 3...\n",
      "layer index: 100 \t total channel: 1024 \t remaining channel: 3\n",
      "Warning: layer 104 all channels pruned, keeping top 3...\n",
      "layer index: 104 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 106 all channels pruned, keeping top 3...\n",
      "layer index: 106 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 108 all channels pruned, keeping top 3...\n",
      "layer index: 108 \t total channel: 1024 \t remaining channel: 3\n",
      "Warning: layer 112 all channels pruned, keeping top 3...\n",
      "layer index: 112 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 114 all channels pruned, keeping top 3...\n",
      "layer index: 114 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 116 \t total channel: 1024 \t remaining channel: 6\n",
      "Warning: layer 121 all channels pruned, keeping top 3...\n",
      "layer index: 121 \t total channel: 512 \t remaining channel: 3\n",
      "Warning: layer 123 all channels pruned, keeping top 3...\n",
      "layer index: 123 \t total channel: 512 \t remaining channel: 3\n",
      "layer index: 125 \t total channel: 2048 \t remaining channel: 69\n",
      "Warning: layer 131 all channels pruned, keeping top 3...\n",
      "layer index: 131 \t total channel: 512 \t remaining channel: 3\n",
      "layer index: 133 \t total channel: 512 \t remaining channel: 10\n",
      "layer index: 135 \t total channel: 2048 \t remaining channel: 24\n",
      "Warning: layer 139 all channels pruned, keeping top 3...\n",
      "layer index: 139 \t total channel: 512 \t remaining channel: 3\n",
      "Warning: layer 141 all channels pruned, keeping top 3...\n",
      "layer index: 141 \t total channel: 512 \t remaining channel: 3\n",
      "Warning: layer 143 all channels pruned, keeping top 3...\n",
      "layer index: 143 \t total channel: 2048 \t remaining channel: 3\n",
      "PRUNE RATIO=0.8986355066299438\n",
      "PREPROCESSING SUCCESSFUL!\n",
      "cfg1: [64, 64, 64, 255, 64, 64, 218, 64, 64, 94, 117, 108, 150, 78, 117, 84, 73, 87, 43, 54, 59, 15, 13, 9, 70, 6, 10, 26, 3, 5, 10, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 69, 3, 10, 24, 3, 3, 3]\n",
      "cfg2: [64, 64, 64, 256, 64, 64, 256, 64, 64, 256, 117, 108, 512, 78, 117, 512, 73, 87, 512, 54, 59, 512, 13, 9, 1024, 6, 10, 1024, 3, 5, 1024, 3, 3, 1024, 3, 3, 1024, 3, 3, 1024, 3, 3, 2048, 3, 10, 2048, 3, 3, 2048]\n"
     ]
    }
   ],
   "source": [
    "for k, m in enumerate((model.modules())):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        weight_copy = m.weight.data.clone()\n",
    "        mask = weight_copy.abs().gt(threshold).float().cuda() # 大於 threshold 的設為 True (1.0)，其餘為 False(0.0)\n",
    "\n",
    "        # 注意: 需自行設計處理剩下channel數為0的情況 (e.g. 至少保留3個channel)\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        if int(torch.sum(mask)) <= 3:\n",
    "            print(f'Warning: layer {k} all channels pruned, keeping top 3...')\n",
    "            _, sorted_idx = torch.sort(weight_copy.abs(), descending=True)\n",
    "            mask[sorted_idx[:3]] = 1.0\n",
    "\n",
    "        # 處理剪枝後的權重\n",
    "        m.weight.data.mul_(mask)\n",
    "        m.bias.data.mul_(mask)\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "        cfg.append(int(torch.sum(mask)))    # 記錄每一層 BN 剩下幾個通道\n",
    "        cfg_mask.append(mask.clone())     # 儲存每層對應的 mask\n",
    "        cfg_origin.append(mask.shape[0])\n",
    "        # if mask.shape[0] != int(torch.sum(mask)):\n",
    "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "            format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "\n",
    "pruned_ratio = pruned/total\n",
    "\n",
    "print(f'PRUNE RATIO={pruned_ratio}')\n",
    "print('PREPROCESSING SUCCESSFUL!')\n",
    "\n",
    "print(f'cfg1: {cfg}')\n",
    "# print(f'cfg_origin: {cfg_origin}')\n",
    "for i in range(len(cfg)):\n",
    "    if (i > 0):\n",
    "        if (cfg_origin[i] > cfg_origin[i - 1]):\n",
    "            cfg[i] = cfg_origin[i]\n",
    "print(f'cfg2: {cfg}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ha2BuBl1ifM"
   },
   "source": [
    "## 建立剪枝模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SlWNdj2f1nWs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 117, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(117, 108, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(108, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 78, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(78, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(78, 117, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(117, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 73, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(73, 87, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(87, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(87, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(54, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(59, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(13, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(9, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(10, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(5, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(10, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel = ResNet50(num_classes=10, cfg=cfg)\n",
    "newmodel.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms9Usgkh1Vbe"
   },
   "source": [
    "### 將原本的模型權重複製到剪枝的模型\n",
    "#### 根據不同層決定要複製什麼權重\n",
    "###### Batch Normalization Layer\n",
    "1.   scale factor\n",
    "2.   bias\n",
    "3.   running mean\n",
    "4.   running variance\n",
    "\n",
    "###### Convolutional Layer\n",
    "1.   weight\n",
    "\n",
    "###### Linear Layer\n",
    "1.   weight\n",
    "2.   bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hQcKuMDee46V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "m0:  torch.Size([64, 3, 3, 3])\n",
      "m1:  torch.Size([64, 3, 3, 3])\n",
      "layer: 7\n",
      "m0:  torch.Size([64, 64, 1, 1])\n",
      "m1:  torch.Size([64, 64, 1, 1])\n",
      "layer: 9\n",
      "m0:  torch.Size([64, 64, 3, 3])\n",
      "m1:  torch.Size([64, 64, 3, 3])\n",
      "layer: 11\n",
      "m0:  torch.Size([256, 64, 1, 1])\n",
      "m1:  torch.Size([256, 64, 1, 1])\n",
      "layer: 15\n",
      "downsample:\n",
      "m0:  torch.Size([256, 64, 1, 1])\n",
      "m1:  torch.Size([256, 64, 1, 1])\n",
      "layer: 17\n",
      "m0:  torch.Size([64, 256, 1, 1])\n",
      "m1:  torch.Size([64, 256, 1, 1])\n",
      "layer: 19\n",
      "m0:  torch.Size([64, 64, 3, 3])\n",
      "m1:  torch.Size([64, 64, 3, 3])\n",
      "layer: 21\n",
      "m0:  torch.Size([256, 64, 1, 1])\n",
      "m1:  torch.Size([256, 64, 1, 1])\n",
      "layer: 25\n",
      "m0:  torch.Size([64, 256, 1, 1])\n",
      "m1:  torch.Size([64, 256, 1, 1])\n",
      "layer: 27\n",
      "m0:  torch.Size([64, 64, 3, 3])\n",
      "m1:  torch.Size([64, 64, 3, 3])\n",
      "layer: 29\n",
      "m0:  torch.Size([256, 64, 1, 1])\n",
      "m1:  torch.Size([256, 64, 1, 1])\n",
      "layer: 34\n",
      "m0:  torch.Size([128, 256, 1, 1])\n",
      "m1:  torch.Size([117, 256, 1, 1])\n",
      "layer: 36\n",
      "m0:  torch.Size([128, 128, 3, 3])\n",
      "m1:  torch.Size([108, 117, 3, 3])\n",
      "layer: 38\n",
      "m0:  torch.Size([512, 128, 1, 1])\n",
      "m1:  torch.Size([512, 108, 1, 1])\n",
      "layer: 42\n",
      "downsample:\n",
      "m0:  torch.Size([512, 256, 1, 1])\n",
      "m1:  torch.Size([512, 256, 1, 1])\n",
      "layer: 44\n",
      "m0:  torch.Size([128, 512, 1, 1])\n",
      "m1:  torch.Size([78, 512, 1, 1])\n",
      "layer: 46\n",
      "m0:  torch.Size([128, 128, 3, 3])\n",
      "m1:  torch.Size([117, 78, 3, 3])\n",
      "layer: 48\n",
      "m0:  torch.Size([512, 128, 1, 1])\n",
      "m1:  torch.Size([512, 117, 1, 1])\n",
      "layer: 52\n",
      "m0:  torch.Size([128, 512, 1, 1])\n",
      "m1:  torch.Size([73, 512, 1, 1])\n",
      "layer: 54\n",
      "m0:  torch.Size([128, 128, 3, 3])\n",
      "m1:  torch.Size([87, 73, 3, 3])\n",
      "layer: 56\n",
      "m0:  torch.Size([512, 128, 1, 1])\n",
      "m1:  torch.Size([512, 87, 1, 1])\n",
      "layer: 60\n",
      "m0:  torch.Size([128, 512, 1, 1])\n",
      "m1:  torch.Size([54, 512, 1, 1])\n",
      "layer: 62\n",
      "m0:  torch.Size([128, 128, 3, 3])\n",
      "m1:  torch.Size([59, 54, 3, 3])\n",
      "layer: 64\n",
      "m0:  torch.Size([512, 128, 1, 1])\n",
      "m1:  torch.Size([512, 59, 1, 1])\n",
      "layer: 69\n",
      "m0:  torch.Size([256, 512, 1, 1])\n",
      "m1:  torch.Size([13, 512, 1, 1])\n",
      "layer: 71\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([9, 13, 3, 3])\n",
      "layer: 73\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 9, 1, 1])\n",
      "layer: 77\n",
      "downsample:\n",
      "m0:  torch.Size([1024, 512, 1, 1])\n",
      "m1:  torch.Size([1024, 512, 1, 1])\n",
      "layer: 79\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([6, 1024, 1, 1])\n",
      "layer: 81\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([10, 6, 3, 3])\n",
      "layer: 83\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 10, 1, 1])\n",
      "layer: 87\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 89\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([5, 3, 3, 3])\n",
      "layer: 91\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 5, 1, 1])\n",
      "layer: 95\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 97\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 99\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 3, 1, 1])\n",
      "layer: 103\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 105\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 107\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 3, 1, 1])\n",
      "layer: 111\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 113\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 115\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 3, 1, 1])\n",
      "layer: 120\n",
      "m0:  torch.Size([512, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 122\n",
      "m0:  torch.Size([512, 512, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 124\n",
      "m0:  torch.Size([2048, 512, 1, 1])\n",
      "m1:  torch.Size([2048, 3, 1, 1])\n",
      "layer: 128\n",
      "downsample:\n",
      "m0:  torch.Size([2048, 1024, 1, 1])\n",
      "m1:  torch.Size([2048, 1024, 1, 1])\n",
      "layer: 130\n",
      "m0:  torch.Size([512, 2048, 1, 1])\n",
      "m1:  torch.Size([3, 2048, 1, 1])\n",
      "layer: 132\n",
      "m0:  torch.Size([512, 512, 3, 3])\n",
      "m1:  torch.Size([10, 3, 3, 3])\n",
      "layer: 134\n",
      "m0:  torch.Size([2048, 512, 1, 1])\n",
      "m1:  torch.Size([2048, 10, 1, 1])\n",
      "layer: 138\n",
      "m0:  torch.Size([512, 2048, 1, 1])\n",
      "m1:  torch.Size([3, 2048, 1, 1])\n",
      "layer: 140\n",
      "m0:  torch.Size([512, 512, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 142\n",
      "m0:  torch.Size([2048, 512, 1, 1])\n",
      "m1:  torch.Size([2048, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "old_modules = list(model.modules())\n",
    "new_modules = list(newmodel.modules())\n",
    "\n",
    "# for i in range(len(cfg_mask)):\n",
    "#     idx = np.squeeze(np.argwhere(np.asarray(cfg_mask[i].cpu().numpy())))\n",
    "#     print(i, \": \", idx.size)\n",
    "\n",
    "layer_id_in_cfg = 0\n",
    "start_mask = torch.ones(3) #3為input channel(R,G,B)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "bn_count = 0\n",
    "\n",
    "\n",
    "layer_id_offset = 0\n",
    "for layer_id in range(len(old_modules)):\n",
    "\n",
    "    m0 = old_modules[layer_id]\n",
    "    m1 = new_modules[layer_id + layer_id_offset]\n",
    "\n",
    "    if type(m0) != type(m1):\n",
    "        layer_id_offset += 2\n",
    "        m1 = new_modules[layer_id + layer_id_offset]\n",
    "\n",
    "        # print(\"old\", layer_id, type(m0))\n",
    "        # print(\"new\", layer_id + layer_id_offset, type(m1), \"\\n\")\n",
    "\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        bn_count += 1\n",
    "        \n",
    "        #### 找出遮罩中非零元素的index ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        if idx1.ndim == 0:\n",
    "            idx1 = np.expand_dims(idx1, 0)\n",
    "\n",
    "\n",
    "        #### 複製weight, bias, running mean,and running variance ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        \n",
    "\n",
    "        if cfg_origin[layer_id_in_cfg] > cfg_origin[layer_id_in_cfg - 1]: # change to origin cfg value\n",
    "            new_w = torch.zeros_like(m0.weight.data)  # 先建立同 shape 的 0 tensor\n",
    "            new_b = torch.zeros_like(m0.bias.data)  # 先建立同 shape 的 0 tensor\n",
    "            new_rm = torch.zeros_like(m0.running_mean)  # 先建立同 shape 的 0 tensor\n",
    "            new_rv = torch.zeros_like(m0.running_var)  # 先建立同 shape 的 0 tensor\n",
    "            new_w[idx1] = m0.weight.data[idx1].clone()\n",
    "            new_b[idx1] = m0.bias.data[idx1].clone()\n",
    "            new_rm[idx1] = m0.running_mean[idx1].clone()\n",
    "            new_rv[idx1] = m0.running_var[idx1].clone()\n",
    "            m1.weight.data = new_w.clone()\n",
    "            m1.bias.data = new_b.clone()\n",
    "            m1.running_mean = new_rm.clone()\n",
    "            m1.running_var = new_rv.clone()\n",
    "        else:\n",
    "            m1.weight.data = m0.weight.data[idx1].clone()\n",
    "            m1.bias.data = m0.bias.data[idx1].clone()\n",
    "            m1.running_mean = m0.running_mean[idx1].clone()\n",
    "            m1.running_var = m0.running_var[idx1].clone()\n",
    "\n",
    "        layer_id_in_cfg += 1\n",
    "        start_mask = end_mask.clone()\n",
    "\n",
    "        #最後一層連接層不做修改\n",
    "        if layer_id_in_cfg < len(cfg_mask):\n",
    "            end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "\n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        print(\"layer:\", layer_id)\n",
    "        # print(\"before parm copy:\")\n",
    "        # print(\"m0: \", m0.weight.shape)\n",
    "        # print(\"m1: \", m1.weight.shape)\n",
    "\n",
    "        w = m0.weight.data.clone()\n",
    "        \n",
    "        # Conv2d weight shape: [out_channels, in_channels, kH, kW]\n",
    "\n",
    "        # 判斷是否為 downsample conv\n",
    "        is_downsample = (\n",
    "            m0.kernel_size == (1, 1)\n",
    "            and (m0.stride != (1, 1))\n",
    "        )\n",
    "\n",
    "        if isinstance(old_modules[layer_id + 1], nn.BatchNorm2d):\n",
    "\n",
    "            # 一般 conv，會被剪 input/output channel\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "\n",
    "            # print(\"this: \", cfg_origin[layer_id_in_cfg], \"next: \", cfg_origin[layer_id_in_cfg + 1], \"last: \", cfg_origin[layer_id_in_cfg - 1])\n",
    "\n",
    "            if cfg_origin[layer_id_in_cfg] > cfg_origin[layer_id_in_cfg - 1]: # change to origin cfg value\n",
    "                new_w = torch.zeros_like(m0.weight.data)  # 先建立同 shape 的 0 tensor\n",
    "                new_w[idx1.tolist(), :, :, :] = w[idx1.tolist(), :, :, :].clone()\n",
    "                new_w = new_w[:, idx0.tolist(), :, :].clone()\n",
    "                m1.weight.data = new_w.clone()\n",
    "            elif cfg_origin[layer_id_in_cfg] < cfg_origin[layer_id_in_cfg - 1]:\n",
    "                new_w = torch.zeros_like(m0.weight.data)  # 先建立同 shape 的 0 tensor\n",
    "                new_w = w[idx1.tolist(), :, :, :].clone()\n",
    "                new_w[ :,idx0.tolist() , :, :] = new_w[:, idx0.tolist(), :, :].clone()\n",
    "                m1.weight.data = new_w.clone()\n",
    "            else:\n",
    "                m1.weight.data = w[idx1.tolist(), :, :, :].clone()\n",
    "                m1.weight.data = m1.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            \n",
    "\n",
    "            # print(\"idx1: \", idx1.size)\n",
    "            # print(\"idx0: \", idx0.size)\n",
    "            \n",
    "\n",
    "        # elif is_downsample:\n",
    "        # else:\n",
    "        #     print(f\"[INFO] Fixing downsample conv: {m0} → {m1}\")\n",
    "        #     # downsample 的輸出應該要和 conv3 的輸出一致\n",
    "        #     idx1 = np.squeeze(np.argwhere(np.asarray(cfg_mask[layer_id_in_cfg - 1].cpu().numpy())))\n",
    "        #     # downsample 通常不剪 input channel，只剪 output channel\n",
    "        #     m1.weight.data = w[idx1.tolist(), :, :, :].clone()\n",
    "        #     # try\n",
    "        #     idx0 = np.squeeze(np.argwhere(np.asarray(cfg_mask[layer_id_in_cfg - 4].cpu().numpy())))\n",
    "        #     m1.weight.data = m1.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "        #     print(\"idx1: \", idx1.size)\n",
    "        #     print(\"idx0: \", idx0.size)\n",
    "\n",
    "        \n",
    "\n",
    "        else:\n",
    "            # 其他層 (例如第一層 conv)\n",
    "            print(\"downsample:\")\n",
    "            m1.weight.data = w.clone()\n",
    "\n",
    "        # print(\"after parm copy:\")\n",
    "        print(\"m0: \", m0.weight.shape)\n",
    "        print(\"m1: \", m1.weight.shape)\n",
    "            \n",
    "\n",
    "\n",
    "    elif isinstance(m0, nn.Linear):\n",
    "\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        if idx0.ndim == 0:\n",
    "            idx0 = np.expand_dims(idx0, 0)\n",
    "\n",
    "        #### 複製weight ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        # m1.weight.data = m0.weight.data[:, idx0.tolist()].clone()\n",
    "        m1.weight.data = torch.zeros_like(m0.weight.data)\n",
    "        m1.weight.data[:, idx0.tolist()] = m0.weight.data[:, idx0.tolist()].clone()\n",
    "\n",
    "        #### 複製bias ####\n",
    "        m1.bias.data = m0.bias.data.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0nUbcNtA_SA"
   },
   "source": [
    "## 測試函數\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Md44Lc-WBIaf"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def test(model):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "        batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "          if CUDA:\n",
    "              data, target = data.cuda(), target.cuda()\n",
    "          data, target = Variable(data), Variable(target)\n",
    "          output = model(data)\n",
    "          pred = output.data.max(1, keepdim=True)[1]\n",
    "          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "          total += target.size(0)\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    return correct / float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFkMmFLo88mc"
   },
   "source": [
    "## 儲存模型並印出結果，以及剪枝後的test acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cuo3HXHt9Ar-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 117, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(117, 108, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(108, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 78, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(78, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(78, 117, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(117, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 73, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(73, 87, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(87, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(87, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(54, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(59, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(13, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(9, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(10, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(5, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(10, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 2183/10000 (21.8%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2183)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, PRUNE_PATH)\n",
    "\n",
    "print(newmodel)\n",
    "model = newmodel.cuda()\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 130318480.0\n",
      "Params: 3736356.0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5           [-1, 64, 16, 16]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "           Conv2d-11          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 16, 16]             512\n",
      "           Conv2d-13          [-1, 256, 16, 16]          16,384\n",
      "             ReLU-14          [-1, 256, 16, 16]               0\n",
      "       Bottleneck-15          [-1, 256, 16, 16]               0\n",
      "           Conv2d-16           [-1, 64, 16, 16]          16,384\n",
      "      BatchNorm2d-17           [-1, 64, 16, 16]             128\n",
      "             ReLU-18           [-1, 64, 16, 16]               0\n",
      "           Conv2d-19           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 16, 16]             128\n",
      "             ReLU-21           [-1, 64, 16, 16]               0\n",
      "           Conv2d-22          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-23          [-1, 256, 16, 16]             512\n",
      "             ReLU-24          [-1, 256, 16, 16]               0\n",
      "       Bottleneck-25          [-1, 256, 16, 16]               0\n",
      "           Conv2d-26           [-1, 64, 16, 16]          16,384\n",
      "      BatchNorm2d-27           [-1, 64, 16, 16]             128\n",
      "             ReLU-28           [-1, 64, 16, 16]               0\n",
      "           Conv2d-29           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-30           [-1, 64, 16, 16]             128\n",
      "             ReLU-31           [-1, 64, 16, 16]               0\n",
      "           Conv2d-32          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-33          [-1, 256, 16, 16]             512\n",
      "             ReLU-34          [-1, 256, 16, 16]               0\n",
      "       Bottleneck-35          [-1, 256, 16, 16]               0\n",
      "           Conv2d-36          [-1, 117, 16, 16]          29,952\n",
      "      BatchNorm2d-37          [-1, 117, 16, 16]             234\n",
      "             ReLU-38          [-1, 117, 16, 16]               0\n",
      "           Conv2d-39            [-1, 108, 8, 8]         113,724\n",
      "      BatchNorm2d-40            [-1, 108, 8, 8]             216\n",
      "             ReLU-41            [-1, 108, 8, 8]               0\n",
      "           Conv2d-42            [-1, 512, 8, 8]          55,296\n",
      "      BatchNorm2d-43            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-44            [-1, 512, 8, 8]         131,072\n",
      "             ReLU-45            [-1, 512, 8, 8]               0\n",
      "       Bottleneck-46            [-1, 512, 8, 8]               0\n",
      "           Conv2d-47             [-1, 78, 8, 8]          39,936\n",
      "      BatchNorm2d-48             [-1, 78, 8, 8]             156\n",
      "             ReLU-49             [-1, 78, 8, 8]               0\n",
      "           Conv2d-50            [-1, 117, 8, 8]          82,134\n",
      "      BatchNorm2d-51            [-1, 117, 8, 8]             234\n",
      "             ReLU-52            [-1, 117, 8, 8]               0\n",
      "           Conv2d-53            [-1, 512, 8, 8]          59,904\n",
      "      BatchNorm2d-54            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-55            [-1, 512, 8, 8]               0\n",
      "       Bottleneck-56            [-1, 512, 8, 8]               0\n",
      "           Conv2d-57             [-1, 73, 8, 8]          37,376\n",
      "      BatchNorm2d-58             [-1, 73, 8, 8]             146\n",
      "             ReLU-59             [-1, 73, 8, 8]               0\n",
      "           Conv2d-60             [-1, 87, 8, 8]          57,159\n",
      "      BatchNorm2d-61             [-1, 87, 8, 8]             174\n",
      "             ReLU-62             [-1, 87, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]          44,544\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       Bottleneck-66            [-1, 512, 8, 8]               0\n",
      "           Conv2d-67             [-1, 54, 8, 8]          27,648\n",
      "      BatchNorm2d-68             [-1, 54, 8, 8]             108\n",
      "             ReLU-69             [-1, 54, 8, 8]               0\n",
      "           Conv2d-70             [-1, 59, 8, 8]          28,674\n",
      "      BatchNorm2d-71             [-1, 59, 8, 8]             118\n",
      "             ReLU-72             [-1, 59, 8, 8]               0\n",
      "           Conv2d-73            [-1, 512, 8, 8]          30,208\n",
      "      BatchNorm2d-74            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-75            [-1, 512, 8, 8]               0\n",
      "       Bottleneck-76            [-1, 512, 8, 8]               0\n",
      "           Conv2d-77             [-1, 13, 8, 8]           6,656\n",
      "      BatchNorm2d-78             [-1, 13, 8, 8]              26\n",
      "             ReLU-79             [-1, 13, 8, 8]               0\n",
      "           Conv2d-80              [-1, 9, 4, 4]           1,053\n",
      "      BatchNorm2d-81              [-1, 9, 4, 4]              18\n",
      "             ReLU-82              [-1, 9, 4, 4]               0\n",
      "           Conv2d-83           [-1, 1024, 4, 4]           9,216\n",
      "      BatchNorm2d-84           [-1, 1024, 4, 4]           2,048\n",
      "           Conv2d-85           [-1, 1024, 4, 4]         524,288\n",
      "             ReLU-86           [-1, 1024, 4, 4]               0\n",
      "       Bottleneck-87           [-1, 1024, 4, 4]               0\n",
      "           Conv2d-88              [-1, 6, 4, 4]           6,144\n",
      "      BatchNorm2d-89              [-1, 6, 4, 4]              12\n",
      "             ReLU-90              [-1, 6, 4, 4]               0\n",
      "           Conv2d-91             [-1, 10, 4, 4]             540\n",
      "      BatchNorm2d-92             [-1, 10, 4, 4]              20\n",
      "             ReLU-93             [-1, 10, 4, 4]               0\n",
      "           Conv2d-94           [-1, 1024, 4, 4]          10,240\n",
      "      BatchNorm2d-95           [-1, 1024, 4, 4]           2,048\n",
      "             ReLU-96           [-1, 1024, 4, 4]               0\n",
      "       Bottleneck-97           [-1, 1024, 4, 4]               0\n",
      "           Conv2d-98              [-1, 3, 4, 4]           3,072\n",
      "      BatchNorm2d-99              [-1, 3, 4, 4]               6\n",
      "            ReLU-100              [-1, 3, 4, 4]               0\n",
      "          Conv2d-101              [-1, 5, 4, 4]             135\n",
      "     BatchNorm2d-102              [-1, 5, 4, 4]              10\n",
      "            ReLU-103              [-1, 5, 4, 4]               0\n",
      "          Conv2d-104           [-1, 1024, 4, 4]           5,120\n",
      "     BatchNorm2d-105           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-106           [-1, 1024, 4, 4]               0\n",
      "      Bottleneck-107           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-108              [-1, 3, 4, 4]           3,072\n",
      "     BatchNorm2d-109              [-1, 3, 4, 4]               6\n",
      "            ReLU-110              [-1, 3, 4, 4]               0\n",
      "          Conv2d-111              [-1, 3, 4, 4]              81\n",
      "     BatchNorm2d-112              [-1, 3, 4, 4]               6\n",
      "            ReLU-113              [-1, 3, 4, 4]               0\n",
      "          Conv2d-114           [-1, 1024, 4, 4]           3,072\n",
      "     BatchNorm2d-115           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-116           [-1, 1024, 4, 4]               0\n",
      "      Bottleneck-117           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-118              [-1, 3, 4, 4]           3,072\n",
      "     BatchNorm2d-119              [-1, 3, 4, 4]               6\n",
      "            ReLU-120              [-1, 3, 4, 4]               0\n",
      "          Conv2d-121              [-1, 3, 4, 4]              81\n",
      "     BatchNorm2d-122              [-1, 3, 4, 4]               6\n",
      "            ReLU-123              [-1, 3, 4, 4]               0\n",
      "          Conv2d-124           [-1, 1024, 4, 4]           3,072\n",
      "     BatchNorm2d-125           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-126           [-1, 1024, 4, 4]               0\n",
      "      Bottleneck-127           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-128              [-1, 3, 4, 4]           3,072\n",
      "     BatchNorm2d-129              [-1, 3, 4, 4]               6\n",
      "            ReLU-130              [-1, 3, 4, 4]               0\n",
      "          Conv2d-131              [-1, 3, 4, 4]              81\n",
      "     BatchNorm2d-132              [-1, 3, 4, 4]               6\n",
      "            ReLU-133              [-1, 3, 4, 4]               0\n",
      "          Conv2d-134           [-1, 1024, 4, 4]           3,072\n",
      "     BatchNorm2d-135           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-136           [-1, 1024, 4, 4]               0\n",
      "      Bottleneck-137           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-138              [-1, 3, 4, 4]           3,072\n",
      "     BatchNorm2d-139              [-1, 3, 4, 4]               6\n",
      "            ReLU-140              [-1, 3, 4, 4]               0\n",
      "          Conv2d-141              [-1, 3, 2, 2]              81\n",
      "     BatchNorm2d-142              [-1, 3, 2, 2]               6\n",
      "            ReLU-143              [-1, 3, 2, 2]               0\n",
      "          Conv2d-144           [-1, 2048, 2, 2]           6,144\n",
      "     BatchNorm2d-145           [-1, 2048, 2, 2]           4,096\n",
      "          Conv2d-146           [-1, 2048, 2, 2]       2,097,152\n",
      "            ReLU-147           [-1, 2048, 2, 2]               0\n",
      "      Bottleneck-148           [-1, 2048, 2, 2]               0\n",
      "          Conv2d-149              [-1, 3, 2, 2]           6,144\n",
      "     BatchNorm2d-150              [-1, 3, 2, 2]               6\n",
      "            ReLU-151              [-1, 3, 2, 2]               0\n",
      "          Conv2d-152             [-1, 10, 2, 2]             270\n",
      "     BatchNorm2d-153             [-1, 10, 2, 2]              20\n",
      "            ReLU-154             [-1, 10, 2, 2]               0\n",
      "          Conv2d-155           [-1, 2048, 2, 2]          20,480\n",
      "     BatchNorm2d-156           [-1, 2048, 2, 2]           4,096\n",
      "            ReLU-157           [-1, 2048, 2, 2]               0\n",
      "      Bottleneck-158           [-1, 2048, 2, 2]               0\n",
      "          Conv2d-159              [-1, 3, 2, 2]           6,144\n",
      "     BatchNorm2d-160              [-1, 3, 2, 2]               6\n",
      "            ReLU-161              [-1, 3, 2, 2]               0\n",
      "          Conv2d-162              [-1, 3, 2, 2]              81\n",
      "     BatchNorm2d-163              [-1, 3, 2, 2]               6\n",
      "            ReLU-164              [-1, 3, 2, 2]               0\n",
      "          Conv2d-165           [-1, 2048, 2, 2]           6,144\n",
      "     BatchNorm2d-166           [-1, 2048, 2, 2]           4,096\n",
      "            ReLU-167           [-1, 2048, 2, 2]               0\n",
      "      Bottleneck-168           [-1, 2048, 2, 2]               0\n",
      "AdaptiveAvgPool2d-169           [-1, 2048, 1, 1]               0\n",
      "          Linear-170                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 3,736,356\n",
      "Trainable params: 3,736,356\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 20.15\n",
      "Params size (MB): 14.25\n",
      "Estimated Total Size (MB): 34.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "from torchsummary import summary\n",
    "\n",
    "##### 使用 thop 計算 FLOPs 和參數數量 #####\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "flops, params = profile(model, inputs=(dummy_input, ))\n",
    "\n",
    "print(f\"FLOPs: {flops}\")\n",
    "print(f\"Params: {params}\")\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
