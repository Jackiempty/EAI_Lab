{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk6d9yOhuSkr"
   },
   "source": [
    "## 掛載雲端硬碟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3NTpFfZGuVSx"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEETyGg0uZnb"
   },
   "source": [
    "## 更改檔案所在路徑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Wum2GQmwucfZ"
   },
   "outputs": [],
   "source": [
    "# # Change to your own folder !!!\n",
    "# %cd /content/drive/MyDrive/your own folder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9NTZ1VEtbV7"
   },
   "source": [
    "## 載入函式庫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vCvF-fM0tfsq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from models.resnet import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X_r4dtMuwbh"
   },
   "source": [
    "## 超參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_2NkY0LyuyQh"
   },
   "outputs": [],
   "source": [
    "DATASET = 'cifar10'\n",
    "TEST_BATCH_SIZE = 1000\n",
    "CUDA = True\n",
    "PRUNE_PERCENT = 0.9 # Change your prune ratio!\n",
    "WEIGHT_PATH = './model_best.pth' # Change to your own folder !!!\n",
    "PRUNE_PATH = './model_prune.pth' # Change to your own folder !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7z4dkhJwB4Z"
   },
   "source": [
    "## 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lpIqnhfKwEcJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING CHECKPOINT ./model_best.pth @EPOCH=38, BEST_PREC1=0.9031999707221985\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(1)\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "\n",
    "model = ResNet50(num_classes=10)\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "if WEIGHT_PATH:\n",
    "    if os.path.isfile(WEIGHT_PATH):\n",
    "        checkpoint = torch.load(WEIGHT_PATH)\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print('LOADING CHECKPOINT {} @EPOCH={}, BEST_PREC1={}'.format(WEIGHT_PATH,checkpoint['epoch'],best_prec1))\n",
    "\n",
    "    else:\n",
    "        print(\"NO CHECKPOINT FOUND\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srauYOD-1vSp"
   },
   "source": [
    "## 進行剪枝\n",
    "#### 計算所有Batch Normalizaiton中的scale factor絕對值大小並排序\n",
    "#### 利用設定好的PRUNE_PERCENT來取得閥值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xgtUBaDw1uuR"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        total += m.weight.data.shape[0]\n",
    "\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        size = m.weight.data.shape[0]\n",
    "        bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "        index += size\n",
    "\n",
    "y, i = torch.sort(bn)\n",
    "\n",
    "threshold_index = int(total * PRUNE_PERCENT)\n",
    "threshold = y[threshold_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66vDWd5BMmph"
   },
   "source": [
    "## 根據Batch Normalization Layer資訊建立CONFIG\n",
    "#### 1. 複製Batch Normalization Layer的weight(也就是scale factor γ)\n",
    "#### 2. 建立mask，大於threshold的index的值會設成1,小於threshold的值會設成0\n",
    "#### 3. mask的值加總後，會是剪枝後Layer對應的輸出channel數\n",
    "#### 4. 最後得到要建立剪枝模型的CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PBklaqUZHnvp"
   },
   "outputs": [],
   "source": [
    "pruned = 0\n",
    "cfg = []  #用來建立剪枝網路的CONFIG\n",
    "cfg_mask = [] #用來幫助剪枝的遮罩\n",
    "cfg_origin = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "10ilGgoZ1SR1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer index: 2 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 8 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 10 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 12 \t total channel: 256 \t remaining channel: 253\n",
      "layer index: 18 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 20 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 22 \t total channel: 256 \t remaining channel: 234\n",
      "layer index: 26 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 28 \t total channel: 64 \t remaining channel: 64\n",
      "layer index: 30 \t total channel: 256 \t remaining channel: 121\n",
      "layer index: 35 \t total channel: 128 \t remaining channel: 116\n",
      "layer index: 37 \t total channel: 128 \t remaining channel: 113\n",
      "layer index: 39 \t total channel: 512 \t remaining channel: 182\n",
      "layer index: 45 \t total channel: 128 \t remaining channel: 114\n",
      "layer index: 47 \t total channel: 128 \t remaining channel: 124\n",
      "layer index: 49 \t total channel: 512 \t remaining channel: 111\n",
      "layer index: 53 \t total channel: 128 \t remaining channel: 74\n",
      "layer index: 55 \t total channel: 128 \t remaining channel: 81\n",
      "layer index: 57 \t total channel: 512 \t remaining channel: 38\n",
      "layer index: 61 \t total channel: 128 \t remaining channel: 23\n",
      "layer index: 63 \t total channel: 128 \t remaining channel: 16\n",
      "layer index: 65 \t total channel: 512 \t remaining channel: 13\n",
      "Warning: layer 70 all channels pruned, keeping top 3...\n",
      "layer index: 70 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 72 all channels pruned, keeping top 3...\n",
      "layer index: 72 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 74 \t total channel: 1024 \t remaining channel: 33\n",
      "Warning: layer 80 all channels pruned, keeping top 3...\n",
      "layer index: 80 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 82 \t total channel: 256 \t remaining channel: 4\n",
      "layer index: 84 \t total channel: 1024 \t remaining channel: 20\n",
      "Warning: layer 88 all channels pruned, keeping top 3...\n",
      "layer index: 88 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 90 all channels pruned, keeping top 3...\n",
      "layer index: 90 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 92 \t total channel: 1024 \t remaining channel: 13\n",
      "Warning: layer 96 all channels pruned, keeping top 3...\n",
      "layer index: 96 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 98 all channels pruned, keeping top 3...\n",
      "layer index: 98 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 100 \t total channel: 1024 \t remaining channel: 14\n",
      "Warning: layer 104 all channels pruned, keeping top 3...\n",
      "layer index: 104 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 106 all channels pruned, keeping top 3...\n",
      "layer index: 106 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 108 \t total channel: 1024 \t remaining channel: 5\n",
      "Warning: layer 112 all channels pruned, keeping top 3...\n",
      "layer index: 112 \t total channel: 256 \t remaining channel: 3\n",
      "Warning: layer 114 all channels pruned, keeping top 3...\n",
      "layer index: 114 \t total channel: 256 \t remaining channel: 3\n",
      "layer index: 116 \t total channel: 1024 \t remaining channel: 8\n",
      "Warning: layer 121 all channels pruned, keeping top 3...\n",
      "layer index: 121 \t total channel: 512 \t remaining channel: 3\n",
      "Warning: layer 123 all channels pruned, keeping top 3...\n",
      "layer index: 123 \t total channel: 512 \t remaining channel: 3\n",
      "layer index: 125 \t total channel: 2048 \t remaining channel: 83\n",
      "layer index: 131 \t total channel: 512 \t remaining channel: 5\n",
      "layer index: 133 \t total channel: 512 \t remaining channel: 6\n",
      "layer index: 135 \t total channel: 2048 \t remaining channel: 11\n",
      "Warning: layer 139 all channels pruned, keeping top 3...\n",
      "layer index: 139 \t total channel: 512 \t remaining channel: 3\n",
      "Warning: layer 141 all channels pruned, keeping top 3...\n",
      "layer index: 141 \t total channel: 512 \t remaining channel: 3\n",
      "Warning: layer 143 all channels pruned, keeping top 3...\n",
      "layer index: 143 \t total channel: 2048 \t remaining channel: 3\n",
      "PRUNE RATIO=0.8982834219932556\n",
      "PREPROCESSING SUCCESSFUL!\n",
      "cfg: [64, 64, 64, 253, 64, 64, 234, 64, 64, 121, 116, 113, 182, 114, 124, 111, 74, 81, 38, 23, 16, 13, 3, 3, 33, 3, 4, 20, 3, 3, 13, 3, 3, 14, 3, 3, 5, 3, 3, 8, 3, 3, 83, 5, 6, 11, 3, 3, 3]\n",
      "cfg_origin: [64, 64, 64, 256, 64, 64, 256, 64, 64, 256, 128, 128, 512, 128, 128, 512, 128, 128, 512, 128, 128, 512, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 512, 512, 2048, 512, 512, 2048, 512, 512, 2048]\n"
     ]
    }
   ],
   "source": [
    "for k, m in enumerate((model.modules())):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        weight_copy = m.weight.data.clone()\n",
    "        mask = weight_copy.abs().gt(threshold).float().cuda() # 大於 threshold 的設為 True (1.0)，其餘為 False(0.0)\n",
    "\n",
    "        # 注意: 需自行設計處理剩下channel數為0的情況 (e.g. 至少保留3個channel)\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        if int(torch.sum(mask)) <= 3:\n",
    "            print(f'Warning: layer {k} all channels pruned, keeping top 3...')\n",
    "            _, sorted_idx = torch.sort(weight_copy.abs(), descending=True)\n",
    "            mask[sorted_idx[:3]] = 1.0\n",
    "\n",
    "        # 處理剪枝後的權重\n",
    "        m.weight.data.mul_(mask)\n",
    "        m.bias.data.mul_(mask)\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "        cfg.append(int(torch.sum(mask)))    # 記錄每一層 BN 剩下幾個通道\n",
    "        cfg_mask.append(mask.clone())     # 儲存每層對應的 mask\n",
    "        cfg_origin.append(mask.shape[0])\n",
    "        # if mask.shape[0] != int(torch.sum(mask)):\n",
    "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "            format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "\n",
    "pruned_ratio = pruned/total\n",
    "\n",
    "print(f'PRUNE RATIO={pruned_ratio}')\n",
    "print('PREPROCESSING SUCCESSFUL!')\n",
    "\n",
    "print(f'cfg: {cfg}')\n",
    "print(f'cfg_origin: {cfg_origin}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ha2BuBl1ifM"
   },
   "source": [
    "## 建立剪枝模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SlWNdj2f1nWs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(234, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(121, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(116, 113, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(113, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(113, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(121, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 114, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(114, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(124, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(111, 74, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(74, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(74, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(81, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(38, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(23, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(13, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(13, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(4, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(20, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(13, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(14, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(5, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(8, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(8, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(5, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(6, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(11, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=3, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel = ResNet50(num_classes=10, cfg=cfg)\n",
    "newmodel.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms9Usgkh1Vbe"
   },
   "source": [
    "### 將原本的模型權重複製到剪枝的模型\n",
    "#### 根據不同層決定要複製什麼權重\n",
    "###### Batch Normalization Layer\n",
    "1.   scale factor\n",
    "2.   bias\n",
    "3.   running mean\n",
    "4.   running variance\n",
    "\n",
    "###### Convolutional Layer\n",
    "1.   weight\n",
    "\n",
    "###### Linear Layer\n",
    "1.   weight\n",
    "2.   bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hQcKuMDee46V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "m0:  torch.Size([64, 3, 3, 3])\n",
      "m1:  torch.Size([64, 3, 3, 3])\n",
      "layer: 7\n",
      "m0:  torch.Size([64, 64, 1, 1])\n",
      "m1:  torch.Size([64, 64, 1, 1])\n",
      "layer: 9\n",
      "m0:  torch.Size([64, 64, 3, 3])\n",
      "m1:  torch.Size([64, 64, 3, 3])\n",
      "layer: 11\n",
      "m0:  torch.Size([256, 64, 1, 1])\n",
      "m1:  torch.Size([256, 64, 1, 1])\n",
      "layer: 15\n",
      "downsample:\n",
      "m0:  torch.Size([256, 64, 1, 1])\n",
      "m1:  torch.Size([256, 64, 1, 1])\n",
      "layer: 17\n",
      "m0:  torch.Size([64, 256, 1, 1])\n",
      "m1:  torch.Size([64, 256, 1, 1])\n",
      "layer: 19\n",
      "m0:  torch.Size([64, 64, 3, 3])\n",
      "m1:  torch.Size([64, 64, 3, 3])\n",
      "layer: 21\n",
      "m0:  torch.Size([256, 64, 1, 1])\n",
      "m1:  torch.Size([256, 64, 1, 1])\n",
      "layer: 25\n",
      "m0:  torch.Size([64, 256, 1, 1])\n",
      "m1:  torch.Size([64, 256, 1, 1])\n",
      "layer: 27\n",
      "m0:  torch.Size([64, 64, 3, 3])\n",
      "m1:  torch.Size([64, 64, 3, 3])\n",
      "layer: 29\n",
      "m0:  torch.Size([256, 64, 1, 1])\n",
      "m1:  torch.Size([256, 64, 1, 1])\n",
      "layer: 34\n",
      "m0:  torch.Size([128, 256, 1, 1])\n",
      "m1:  torch.Size([116, 256, 1, 1])\n",
      "layer: 36\n",
      "m0:  torch.Size([128, 128, 3, 3])\n",
      "m1:  torch.Size([113, 116, 3, 3])\n",
      "layer: 38\n",
      "m0:  torch.Size([512, 128, 1, 1])\n",
      "m1:  torch.Size([512, 113, 1, 1])\n",
      "layer: 42\n",
      "downsample:\n",
      "m0:  torch.Size([512, 256, 1, 1])\n",
      "m1:  torch.Size([512, 256, 1, 1])\n",
      "layer: 44\n",
      "m0:  torch.Size([128, 512, 1, 1])\n",
      "m1:  torch.Size([114, 512, 1, 1])\n",
      "layer: 46\n",
      "m0:  torch.Size([128, 128, 3, 3])\n",
      "m1:  torch.Size([124, 114, 3, 3])\n",
      "layer: 48\n",
      "m0:  torch.Size([512, 128, 1, 1])\n",
      "m1:  torch.Size([512, 124, 1, 1])\n",
      "layer: 52\n",
      "m0:  torch.Size([128, 512, 1, 1])\n",
      "m1:  torch.Size([74, 512, 1, 1])\n",
      "layer: 54\n",
      "m0:  torch.Size([128, 128, 3, 3])\n",
      "m1:  torch.Size([81, 74, 3, 3])\n",
      "layer: 56\n",
      "m0:  torch.Size([512, 128, 1, 1])\n",
      "m1:  torch.Size([512, 81, 1, 1])\n",
      "layer: 60\n",
      "m0:  torch.Size([128, 512, 1, 1])\n",
      "m1:  torch.Size([23, 512, 1, 1])\n",
      "layer: 62\n",
      "m0:  torch.Size([128, 128, 3, 3])\n",
      "m1:  torch.Size([16, 23, 3, 3])\n",
      "layer: 64\n",
      "m0:  torch.Size([512, 128, 1, 1])\n",
      "m1:  torch.Size([512, 16, 1, 1])\n",
      "layer: 69\n",
      "m0:  torch.Size([256, 512, 1, 1])\n",
      "m1:  torch.Size([3, 512, 1, 1])\n",
      "layer: 71\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 73\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 3, 1, 1])\n",
      "layer: 77\n",
      "downsample:\n",
      "m0:  torch.Size([1024, 512, 1, 1])\n",
      "m1:  torch.Size([1024, 512, 1, 1])\n",
      "layer: 79\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 81\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([4, 3, 3, 3])\n",
      "layer: 83\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 4, 1, 1])\n",
      "layer: 87\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 89\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 91\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 3, 1, 1])\n",
      "layer: 95\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 97\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 99\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 3, 1, 1])\n",
      "layer: 103\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 105\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 107\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 3, 1, 1])\n",
      "layer: 111\n",
      "m0:  torch.Size([256, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 113\n",
      "m0:  torch.Size([256, 256, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 115\n",
      "m0:  torch.Size([1024, 256, 1, 1])\n",
      "m1:  torch.Size([1024, 3, 1, 1])\n",
      "layer: 120\n",
      "m0:  torch.Size([512, 1024, 1, 1])\n",
      "m1:  torch.Size([3, 1024, 1, 1])\n",
      "layer: 122\n",
      "m0:  torch.Size([512, 512, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 124\n",
      "m0:  torch.Size([2048, 512, 1, 1])\n",
      "m1:  torch.Size([2048, 3, 1, 1])\n",
      "layer: 128\n",
      "downsample:\n",
      "m0:  torch.Size([2048, 1024, 1, 1])\n",
      "m1:  torch.Size([2048, 1024, 1, 1])\n",
      "layer: 130\n",
      "m0:  torch.Size([512, 2048, 1, 1])\n",
      "m1:  torch.Size([5, 2048, 1, 1])\n",
      "layer: 132\n",
      "m0:  torch.Size([512, 512, 3, 3])\n",
      "m1:  torch.Size([6, 5, 3, 3])\n",
      "layer: 134\n",
      "m0:  torch.Size([2048, 512, 1, 1])\n",
      "m1:  torch.Size([2048, 6, 1, 1])\n",
      "layer: 138\n",
      "m0:  torch.Size([512, 2048, 1, 1])\n",
      "m1:  torch.Size([3, 2048, 1, 1])\n",
      "layer: 140\n",
      "m0:  torch.Size([512, 512, 3, 3])\n",
      "m1:  torch.Size([3, 3, 3, 3])\n",
      "layer: 142\n",
      "m0:  torch.Size([2048, 512, 1, 1])\n",
      "m1:  torch.Size([2048, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "old_modules = list(model.modules())\n",
    "new_modules = list(newmodel.modules())\n",
    "\n",
    "# for i in range(len(cfg_mask)):\n",
    "#     idx = np.squeeze(np.argwhere(np.asarray(cfg_mask[i].cpu().numpy())))\n",
    "#     print(i, \": \", idx.size)\n",
    "\n",
    "layer_id_in_cfg = 0\n",
    "start_mask = torch.ones(3) #3為input channel(R,G,B)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "bn_count = 0\n",
    "\n",
    "\n",
    "layer_id_offset = 0\n",
    "for layer_id in range(len(old_modules)):\n",
    "\n",
    "    m0 = old_modules[layer_id]\n",
    "    m1 = new_modules[layer_id + layer_id_offset]\n",
    "\n",
    "    if type(m0) != type(m1):\n",
    "        layer_id_offset += 2\n",
    "        m1 = new_modules[layer_id + layer_id_offset]\n",
    "\n",
    "        # print(\"old\", layer_id, type(m0))\n",
    "        # print(\"new\", layer_id + layer_id_offset, type(m1), \"\\n\")\n",
    "\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        bn_count += 1\n",
    "        \n",
    "        #### 找出遮罩中非零元素的index ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        if idx1.ndim == 0:\n",
    "            idx1 = np.expand_dims(idx1, 0)\n",
    "\n",
    "\n",
    "        #### 複製weight, bias, running mean,and running variance ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        m1.weight.data = m0.weight.data[idx1].clone()\n",
    "        m1.bias.data = m0.bias.data[idx1].clone()\n",
    "        m1.running_mean = m0.running_mean[idx1].clone()\n",
    "        m1.running_var = m0.running_var[idx1].clone()\n",
    "\n",
    "        layer_id_in_cfg += 1\n",
    "        start_mask = end_mask.clone()\n",
    "\n",
    "        #最後一層連接層不做修改\n",
    "        if layer_id_in_cfg < len(cfg_mask):\n",
    "            end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "\n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        print(\"layer:\", layer_id)\n",
    "        # print(\"before parm copy:\")\n",
    "        # print(\"m0: \", m0.weight.shape)\n",
    "        # print(\"m1: \", m1.weight.shape)\n",
    "\n",
    "        w = m0.weight.data.clone()\n",
    "        \n",
    "        # Conv2d weight shape: [out_channels, in_channels, kH, kW]\n",
    "\n",
    "        # 判斷是否為 downsample conv\n",
    "        is_downsample = (\n",
    "            m0.kernel_size == (1, 1)\n",
    "            and (m0.stride != (1, 1))\n",
    "        )\n",
    "\n",
    "        if isinstance(old_modules[layer_id + 1], nn.BatchNorm2d):\n",
    "\n",
    "            # 一般 conv，會被剪 input/output channel\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "\n",
    "            # print(\"this: \", cfg_origin[layer_id_in_cfg], \"next: \", cfg_origin[layer_id_in_cfg + 1], \"last: \", cfg_origin[layer_id_in_cfg - 1])\n",
    "\n",
    "            if cfg_origin[layer_id_in_cfg] > cfg_origin[layer_id_in_cfg - 1]: # change to origin cfg value\n",
    "                new_w = torch.zeros_like(m0.weight.data)  # 先建立同 shape 的 0 tensor\n",
    "                new_w[idx1.tolist(), :, :, :] = w[idx1.tolist(), :, :, :].clone()\n",
    "                new_w = new_w[:, idx0.tolist(), :, :].clone()\n",
    "                m1.weight.data = new_w.clone()\n",
    "            elif cfg_origin[layer_id_in_cfg] < cfg_origin[layer_id_in_cfg - 1]:\n",
    "                new_w = torch.zeros_like(m0.weight.data)  # 先建立同 shape 的 0 tensor\n",
    "                new_w = w[idx1.tolist(), :, :, :].clone()\n",
    "                new_w[ :,idx0.tolist() , :, :] = new_w[:, idx0.tolist(), :, :].clone()\n",
    "                m1.weight.data = new_w.clone()\n",
    "            else:\n",
    "                m1.weight.data = w[idx1.tolist(), :, :, :].clone()\n",
    "                m1.weight.data = m1.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            \n",
    "\n",
    "            # print(\"idx1: \", idx1.size)\n",
    "            # print(\"idx0: \", idx0.size)\n",
    "            \n",
    "\n",
    "        # elif is_downsample:\n",
    "        # else:\n",
    "        #     print(f\"[INFO] Fixing downsample conv: {m0} → {m1}\")\n",
    "        #     # downsample 的輸出應該要和 conv3 的輸出一致\n",
    "        #     idx1 = np.squeeze(np.argwhere(np.asarray(cfg_mask[layer_id_in_cfg - 1].cpu().numpy())))\n",
    "        #     # downsample 通常不剪 input channel，只剪 output channel\n",
    "        #     m1.weight.data = w[idx1.tolist(), :, :, :].clone()\n",
    "        #     # try\n",
    "        #     idx0 = np.squeeze(np.argwhere(np.asarray(cfg_mask[layer_id_in_cfg - 4].cpu().numpy())))\n",
    "        #     m1.weight.data = m1.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "        #     print(\"idx1: \", idx1.size)\n",
    "        #     print(\"idx0: \", idx0.size)\n",
    "\n",
    "        \n",
    "\n",
    "        else:\n",
    "            # 其他層 (例如第一層 conv)\n",
    "            print(\"downsample:\")\n",
    "            m1.weight.data = w.clone()\n",
    "\n",
    "        # print(\"after parm copy:\")\n",
    "        print(\"m0: \", m0.weight.shape)\n",
    "        print(\"m1: \", m1.weight.shape)\n",
    "            \n",
    "\n",
    "\n",
    "    elif isinstance(m0, nn.Linear):\n",
    "\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        if idx0.ndim == 0:\n",
    "            idx0 = np.expand_dims(idx0, 0)\n",
    "\n",
    "        #### 複製weight ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        m1.weight.data = m0.weight.data[:, idx0.tolist()].clone()\n",
    "\n",
    "        #### 複製bias ####\n",
    "        m1.bias.data = m0.bias.data.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0nUbcNtA_SA"
   },
   "source": [
    "## 測試函數\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Md44Lc-WBIaf"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def test(model):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "        batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "          if CUDA:\n",
    "              data, target = data.cuda(), target.cuda()\n",
    "          data, target = Variable(data), Variable(target)\n",
    "          output = model(data)\n",
    "          pred = output.data.max(1, keepdim=True)[1]\n",
    "          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "          total += target.size(0)\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    return correct / float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFkMmFLo88mc"
   },
   "source": [
    "## 儲存模型並印出結果，以及剪枝後的test acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cuo3HXHt9Ar-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 1 has a total capacity of 47.41 GiB of which 179.94 MiB is free. Process 274736 has 15.99 GiB memory in use. Process 274920 has 30.78 GiB memory in use. Including non-PyTorch memory, this process has 448.00 MiB memory in use. Of the allocated memory 121.16 MiB is allocated by PyTorch, and 22.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model = newmodel.cuda()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# checkpoint = torch.load(PRUNE_PATH)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# model.load_state_dict(checkpoint['state_dict'])\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m     16\u001b[39m     data, target = data.cuda(), target.cuda()\n\u001b[32m     17\u001b[39m data, target = Variable(data), Variable(target)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m pred = output.data.max(\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m1\u001b[39m]\n\u001b[32m     20\u001b[39m correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Course/EAI_Lab/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Course/EAI_Lab/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Course/EAI_Lab/LAB2/models/resnet.py:142\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28mself\u001b[39m.bn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m    143\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.maxpool(x)\n\u001b[32m    145\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.layer1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Course/EAI_Lab/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Course/EAI_Lab/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Course/EAI_Lab/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Course/EAI_Lab/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 1 has a total capacity of 47.41 GiB of which 179.94 MiB is free. Process 274736 has 15.99 GiB memory in use. Process 274920 has 30.78 GiB memory in use. Including non-PyTorch memory, this process has 448.00 MiB memory in use. Of the allocated memory 121.16 MiB is allocated by PyTorch, and 22.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, PRUNE_PATH)\n",
    "\n",
    "# print(newmodel)\n",
    "model = newmodel.cuda()\n",
    "# checkpoint = torch.load(PRUNE_PATH)\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "from torchsummary import summary\n",
    "\n",
    "##### 使用 thop 計算 FLOPs 和參數數量 #####\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "flops, params = profile(model, inputs=(dummy_input, ))\n",
    "\n",
    "print(f\"FLOPs: {flops}\")\n",
    "print(f\"Params: {params}\")\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EAI_Lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
