{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KRm0_WztAPe"
   },
   "source": [
    "# 2025 EAI Lab 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e7m9tHTpR0H"
   },
   "source": [
    "## Topic 1 : From PyTorch To ONNX\n",
    "\n",
    "### Steps:\n",
    "1.   Define Model Architecture\n",
    "2.   Load Weight\n",
    "3.   Export ONNX File\n",
    "4.   Quantize To INT8\n",
    "5.   Building Session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vt7LM45spK0Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: onnx in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (1.20.0)\n",
      "Requirement already satisfied: onnxscript in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (0.5.6)\n",
      "Requirement already satisfied: onnxruntime in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (1.23.2)\n",
      "Requirement already satisfied: onnxruntime-tools in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: gradio in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (6.0.2)\n",
      "Requirement already satisfied: filelock in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: numpy in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnx) (6.32.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnx) (0.5.4)\n",
      "Requirement already satisfied: onnx_ir<2,>=0.1.12 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnxscript) (0.1.12)\n",
      "Requirement already satisfied: packaging in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnxscript) (25.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnxruntime) (25.9.23)\n",
      "Requirement already satisfied: psutil in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnxruntime-tools) (7.1.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnxruntime-tools) (9.0.0)\n",
      "Requirement already satisfied: py3nvml in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from onnxruntime-tools) (0.2.7)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (4.12.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.123.5)\n",
      "Requirement already satisfied: ffmpy in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (1.1.7)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.12.4)\n",
      "Requirement already satisfied: pydub in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (6.0.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: xmltodict in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from py3nvml->onnxruntime-tools) (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \\\n",
    "    torch torchvision torchaudio \\\n",
    "    onnx onnxscript onnxruntime onnxruntime-tools \\\n",
    "    gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MCKZlTEIqkOD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import onnx\n",
    "\n",
    "# TODO\n",
    "# Design Your ResNet18 Model\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, ResBlock, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResBlock, 64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)  # First block may have stride > 1, others stride=1\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.inchannel, channels, s))\n",
    "            self.inchannel = channels  # Update inchannel for the next block\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RUErZRINpUU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ResNet18([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ResNet18([...]` with `torch.export.export(..., strict=False)`... âœ…\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... âœ…\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... âœ…\n",
      "Applied 40 of general pattern rewrite rules.\n"
     ]
    }
   ],
   "source": [
    "torch_model = ResNet18(ResBlock=BasicBlock, num_classes=10)\n",
    "dummy_input = (torch.randn(1, 3, 32, 32),)\n",
    "\n",
    "def export_onnx(model, dummy, path):\n",
    "    state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "    # TODO : load state dict\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    # TODO : Export ONNX FILE\n",
    "    torch.onnx.export(\n",
    "        model,                     # the model instance\n",
    "        dummy,                     # example input tuple\n",
    "        \"n26140692_FP32.onnx\",     # output ONNX file\n",
    "        input_names=[\"input\"],     # optional: name of input node\n",
    "        output_names=[\"output\"],   # optional: name of output node\n",
    "        opset_version=18           # recommended ONNX opset version\n",
    "    )\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    export_onnx(model=torch_model, dummy=dummy_input, path=\"best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ é–‹å§‹ä¿®å¾©æ¨¡åž‹: n26140692_FP32.onnx\n",
      "âœ… æ¨¡åž‹è¼‰å…¥æˆåŠŸ (åŒ…å«å¤–éƒ¨è³‡æ–™)\n",
      "âœ… æ¨¡åž‹å·²é‡æ–°å„²å­˜ç‚ºå–®ä¸€æª”æ¡ˆ\n",
      "ðŸ—‘ï¸ å·²åˆªé™¤å¤šé¤˜çš„è³‡æ–™æª”: n26140692_FP32.onnx.data\n",
      "ðŸ“Š ä¿®å¾©å¾Œæª”æ¡ˆå¤§å°: 42.65 MB\n",
      "ðŸŽ‰ ä¿®å¾©å®Œæˆï¼ç¾åœ¨ Gradio æ‡‰è©²å¯ä»¥è®€å–äº†ã€‚\n"
     ]
    }
   ],
   "source": [
    "# set path\n",
    "onnx_path = \"n26140692_FP32.onnx\"\n",
    "data_path = \"n26140692_FP32.onnx.data\"\n",
    "print(f\"start repairing: {onnx_path}...\")\n",
    "\n",
    "try:\n",
    "    # 1. load model\n",
    "    model = onnx.load(onnx_path)\n",
    "    print(\"model loaded...\")\n",
    "\n",
    "    # 2. force overwrite\n",
    "    onnx.save(model, onnx_path)\n",
    "    print(\"model merged...\")\n",
    "\n",
    "    # 3. delete reduntant *.data file\n",
    "    if os.path.exists(data_path):\n",
    "        os.remove(data_path)\n",
    "        print(f\"reduntant file deleted...: {data_path}\")\n",
    "    else:\n",
    "        print(\"no *.data found\")\n",
    "\n",
    "    # 4. final confirmation\n",
    "    size_mb = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "    print(f\"file size after repairing {size_mb:.2f} MB\")\n",
    "    \n",
    "    if size_mb > 40:\n",
    "        print(\"done repairing !\")\n",
    "    else:\n",
    "        print(\"warning! file still unnormally small\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"failed repairing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PnBfgSxfpUzD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calib will use input name: input\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np\n",
    "from PIL import Image\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import CalibrationDataReader\n",
    "\n",
    "CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n",
    "CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n",
    "\n",
    "def preprocess_32x32(pil_img: Image.Image) -> np.ndarray:\n",
    "    arr = np.asarray(pil_img.convert(\"RGB\").resize((32, 32)), dtype=np.float32) / 255.0\n",
    "    arr = (arr - CIFAR10_MEAN) / CIFAR10_STD\n",
    "    return arr.transpose(2, 0, 1)[None, ...]  # (1,3,32,32)\n",
    "\n",
    "class CIFARLikeCalibReader(CalibrationDataReader):\n",
    "    def __init__(self, image_dir: str = None, input_name: str = \"input\",\n",
    "                 batch_size: int = 32, num_batches: int = 10):\n",
    "        self.input_name  = input_name\n",
    "        self.batch_size  = batch_size\n",
    "        self.num_batches = num_batches\n",
    "        self.paths = []\n",
    "        if image_dir and os.path.isdir(image_dir):\n",
    "            for f in os.listdir(image_dir):\n",
    "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "                    self.paths.append(os.path.join(image_dir, f))\n",
    "        self._mode_random = len(self.paths) == 0\n",
    "        self._pos = 0\n",
    "        self._emitted = 0\n",
    "\n",
    "    def get_next(self):\n",
    "        if self._emitted >= self.num_batches:\n",
    "            return None\n",
    "        if self._mode_random:\n",
    "            batch = np.random.randn(self.batch_size, 3, 32, 32).astype(np.float32)\n",
    "        else:\n",
    "            items = []\n",
    "            for _ in range(self.batch_size):\n",
    "                if self._pos >= len(self.paths):\n",
    "                    break\n",
    "                img = Image.open(self.paths[self._pos])\n",
    "                self._pos += 1\n",
    "                items.append(preprocess_32x32(img))\n",
    "            if not items:\n",
    "                return None\n",
    "            batch = np.concatenate(items, axis=0).astype(np.float32)\n",
    "        self._emitted += 1\n",
    "        return {self.input_name: batch}\n",
    "\n",
    "    def rewind(self):\n",
    "        self._pos = 0\n",
    "        self._emitted = 0\n",
    "\n",
    "FP32_MODEL = \"n26140692_FP32.onnx\"\n",
    "INT8_MODEL = \"n26140692_INT8.onnx\"\n",
    "\n",
    "\n",
    "_tmp = ort.InferenceSession(FP32_MODEL, providers=[\"CPUExecutionProvider\"])\n",
    "INPUT_NAME = _tmp.get_inputs()[0].name\n",
    "print(\"Calib will use input name:\", INPUT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9_HL4D23phIN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Running Model Pre-processing...\n",
      "Step 2: Running Quantization...\n",
      "Saved INT8 model: n26140692_INT8.onnx\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_static, QuantType, CalibrationMethod\n",
    "from onnxruntime.quantization.preprocess import quant_pre_process\n",
    "\n",
    "reader = CIFARLikeCalibReader(\n",
    "    image_dir=None,\n",
    "    input_name=INPUT_NAME,\n",
    "    batch_size=1,\n",
    "    num_batches=50\n",
    ")\n",
    "\n",
    "def quantize_to_int8(fp32_path, int8_path, reader, method=\"MinMax\"):\n",
    "    preprocessed_model_path = fp32_path.replace(\".onnx\", \"_pre.onnx\")\n",
    "\n",
    "    print(\"Step 1: Running Model Pre-processing...\")\n",
    "\n",
    "    quant_pre_process(\n",
    "        input_model_path=fp32_path,\n",
    "        output_model_path=preprocessed_model_path\n",
    "    )\n",
    "\n",
    "    print(\"Step 2: Running Quantization...\")\n",
    "    # Todo : quantize_static\n",
    "    quantize_static(\n",
    "        model_input=preprocessed_model_path,\n",
    "        model_output=int8_path,\n",
    "        calibration_data_reader=reader,\n",
    "        quant_format=ort.quantization.QuantFormat.QDQ,\n",
    "        per_channel=True,\n",
    "        weight_type=QuantType.QInt8,\n",
    "        activation_type=QuantType.QUInt8,\n",
    "        reduce_range=False,\n",
    "        calibrate_method=CalibrationMethod.MinMax,\n",
    "        op_types_to_quantize=[\"Conv\",\"MatMul\",\"Gemm\"]\n",
    "    )\n",
    "    print(\"Saved INT8 model:\", INT8_MODEL)\n",
    "\n",
    "quantize_to_int8(FP32_MODEL, INT8_MODEL, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VYZIE2Rdpj3G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Check] relative L2 diff FP32 vs INT8: 0.013204\n",
      "FP32 avg sec: 0.006542115211486816\n",
      "INT8 avg sec: 0.0020003461837768553\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "def run(sess, x):\n",
    "    return sess.run(None, {sess.get_inputs()[0].name: x})[0]\n",
    "\n",
    "x_demo = np.random.randn(1,3,32,32).astype(np.float32)\n",
    "\n",
    "# Todo : build session function\n",
    "def build_session(model_path, providers):\n",
    "  sess = ort.InferenceSession(model_path, providers=providers)\n",
    "  return sess\n",
    "\n",
    "\n",
    "\n",
    "sess_fp32 = build_session(model_path=FP32_MODEL, providers=[\"CPUExecutionProvider\"])\n",
    "sess_int8 = build_session(model_path=INT8_MODEL, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "y_fp32 = run(sess_fp32, x_demo)\n",
    "y_int8 = run(sess_int8, x_demo)\n",
    "\n",
    "l2_rel = np.linalg.norm(y_fp32 - y_int8) / (np.linalg.norm(y_fp32) + 1e-12)\n",
    "print(f\"[Check] relative L2 diff FP32 vs INT8: {l2_rel:.6f}\")\n",
    "\n",
    "def bench(sess, x, n=50):\n",
    "    t0 = time.time()\n",
    "    for _ in range(n):\n",
    "        sess.run(None, {sess.get_inputs()[0].name: x})\n",
    "    return (time.time() - t0) / n\n",
    "\n",
    "print(\"FP32 avg sec:\", bench(sess_fp32, x_demo))\n",
    "print(\"INT8 avg sec:\", bench(sess_int8, x_demo))\n",
    "\n",
    "so = ort.SessionOptions()\n",
    "so.enable_profiling = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeFccLG1pehx"
   },
   "source": [
    "## Topic 2 : Gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qFNo0K7gvJqd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (6.0.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (4.12.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.123.5)\n",
      "Requirement already satisfied: ffmpy in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (1.1.7)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: packaging in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.12.4)\n",
      "Requirement already satisfied: pydub in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (6.0.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: fsspec in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from gradio-client==2.0.1->gradio) (2025.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.19.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_vE9Tel_tI76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://b3249f1bef931d3037.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b3249f1bef931d3037.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "# ====== Config ======\n",
    "MODEL_PATH_INT8 = \"n26140692_INT8.onnx\"   # INT8 ONNX Model\n",
    "MODEL_PATH_FP32 = \"n26140692_FP32.onnx\"     # FP32 ONNX Model\n",
    "LABELS = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "# CIFAR-10 Normalization Parameter\n",
    "CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n",
    "CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n",
    "\n",
    "# ====== Utils ======\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x - np.max(x)\n",
    "    ex = np.exp(x)\n",
    "    return ex / np.sum(ex)\n",
    "\n",
    "# TODO : preprocess input image function\n",
    "def preprocess(image: Image.Image) -> np.ndarray:\n",
    "    \"\"\"Input PIL Image â†’ (1,3,32,32) float32\"\"\"\n",
    "    if not isinstance(image, Image.Image):\n",
    "        raise ValueError(\"Please Upload Image\")\n",
    "\n",
    "    # 1. Resize to 32x32 & Convert to RGB\n",
    "    img = image.convert(\"RGB\").resize((32, 32))\n",
    "    \n",
    "    # 2. To Numpy & Scale to [0, 1]\n",
    "    arr = np.array(img, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # 3. Normalize (Standardization)\n",
    "    arr = (arr - CIFAR10_MEAN) / CIFAR10_STD\n",
    "    \n",
    "    # 4. Transpose (H, W, C) -> (C, H, W)\n",
    "    arr = arr.transpose(2, 0, 1)\n",
    "    \n",
    "    # 5. Add Batch Dimension -> (1, C, H, W)\n",
    "    arr = np.expand_dims(arr, 0)\n",
    "\n",
    "    return arr\n",
    "\n",
    "# ====== ONNX Sessions ======\n",
    "# providers = ort.get_available_providers()\n",
    "providers = ['CPUExecutionProvider']\n",
    "\n",
    "sess_int8 = build_session(MODEL_PATH_INT8, providers=providers)\n",
    "in_int8  = sess_int8.get_inputs()[0].name\n",
    "out_int8 = sess_int8.get_outputs()[0].name\n",
    "\n",
    "\n",
    "try:\n",
    "    sess_fp32 = build_session(MODEL_PATH_FP32, providers=providers)\n",
    "    in_fp32  = sess_fp32.get_inputs()[0].name\n",
    "    out_fp32 = sess_fp32.get_outputs()[0].name\n",
    "    _fp32_err = \"\"\n",
    "except Exception as e:\n",
    "    sess_fp32, in_fp32, out_fp32 = None, None, None\n",
    "    _fp32_err = f\"[FP32 load failure] {type(e).__name__}: {e}\"\n",
    "\n",
    "# ====== Compare FP32 and INT8 ======\n",
    "# TODO : Compare FP32 and INT8\n",
    "def compare_fp32_int8(image: Image.Image):\n",
    "    if image is None:\n",
    "        return {}, {}, \"Please Upload Your Imageã€‚\"\n",
    "    if sess_fp32 is None:\n",
    "        return {}, {}, (_fp32_err or \"The FP32 model has not been provided, so a comparison cannot be made.\")\n",
    "\n",
    "    x = preprocess(image)\n",
    "\n",
    "    # Your progarm\n",
    "    # --- Run FP32 ---\n",
    "    t0 = time.time()\n",
    "    res_fp32 = sess_fp32.run([out_fp32], {in_fp32: x})[0].squeeze().astype(np.float32)\n",
    "    t1 = time.time()\n",
    "    fp32_ms = (t1 - t0) * 1000\n",
    "\n",
    "    # --- Run INT8 ---\n",
    "    t0 = time.time()\n",
    "    res_int8 = sess_int8.run([out_int8], {in_int8: x})[0].squeeze().astype(np.float32)\n",
    "    t1 = time.time()\n",
    "    int8_ms = (t1 - t0) * 1000\n",
    "\n",
    "\n",
    "    p_fp32 = softmax_np(res_fp32)\n",
    "    p_int8 = softmax_np(res_int8)\n",
    "\n",
    "    def top3_map(p):\n",
    "        idx = np.argpartition(p, -3)[-3:]\n",
    "        idx = idx[np.argsort(p[idx])[::-1]]\n",
    "        return {LABELS[i]: float(p[i]) for i in idx}\n",
    "\n",
    "    top3_fp32 = top3_map(p_fp32)\n",
    "    top3_int8 = top3_map(p_int8)\n",
    "\n",
    "    speedup = fp32_ms / int8_ms if int8_ms > 0 else 0\n",
    "    summary = (\n",
    "        f\"FP32 inference time: {fp32_ms:.2f} ms\\n\"\n",
    "        f\"INT8 inference time: {int8_ms:.2f} ms\\n\"\n",
    "        f\"Speedup (FP32/INT8): {speedup:.2f}Ã—\"\n",
    "    )\n",
    "    return top3_fp32, top3_int8, summary\n",
    "\n",
    "# ====== Gradio UI ======\n",
    "# TODO : Building GUI Interface\n",
    "demo = gr.Interface(\n",
    "    fn = compare_fp32_int8,\n",
    "    inputs = gr.Image(type=\"pil\", label=\"Upload Image\"),\n",
    "    outputs = [\n",
    "        gr.Label(num_top_classes=3, label=\"FP32 Prediction (Original)\"),\n",
    "        gr.Label(num_top_classes=3, label=\"INT8 Prediction (Quantized)\"),\n",
    "        gr.Textbox(label=\"Performance Comparison\")\n",
    "    ],\n",
    "    title = \"ONNX Quantization Demo: FP32 vs INT8\",\n",
    "    description = \"Compare the accuracy and speed of the original ResNet model vs. the Quantized INT8 model on CIFAR-10.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # TODO : building a public web\n",
    "    demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOV/rmsswwtq7Dm7IE3hnwD",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
