{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgVOunpmwdT5"
      },
      "source": [
        "# Knowledge Distillation\n",
        "- The concept of **knowledge distillation** is to utilize class probabilities of a higher-capacity model (teacher) as soft targets of a smaller model (student)\n",
        "- The implement processes can be divided into several stages:\n",
        "  1. Finish the `ResNet()` classes\n",
        "  2. Train the teacher model (ResNet50) and the student model (ResNet18) from scratch, i.e. **without KD**\n",
        "  3. Define the `Distiller()` class and `loss_re()`, `loss_fe()` functions\n",
        "  4. Train the student model **with KD** from the teacher model in two different ways, response-based and feature based distillation\n",
        "  5. Comparison of student models w/ & w/o KD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w40lLxA3wdT7"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:46.742442Z",
          "iopub.status.busy": "2025-09-15T17:20:46.742139Z",
          "iopub.status.idle": "2025-09-15T17:20:56.618435Z",
          "shell.execute_reply": "2025-09-15T17:20:56.617889Z",
          "shell.execute_reply.started": "2025-09-15T17:20:46.742411Z"
        },
        "id": "NivvmktxwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:56.619518Z",
          "iopub.status.busy": "2025-09-15T17:20:56.619135Z",
          "iopub.status.idle": "2025-09-15T17:20:56.709343Z",
          "shell.execute_reply": "2025-09-15T17:20:56.708758Z",
          "shell.execute_reply.started": "2025-09-15T17:20:56.619491Z"
        },
        "id": "3n9ohVimwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npQT5vdwwdT9"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:56.711171Z",
          "iopub.status.busy": "2025-09-15T17:20:56.710947Z",
          "iopub.status.idle": "2025-09-15T17:21:02.244060Z",
          "shell.execute_reply": "2025-09-15T17:21:02.243410Z",
          "shell.execute_reply.started": "2025-09-15T17:20:56.711154Z"
        },
        "id": "4WprgXfzwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "validation_split = 0.1\n",
        "batch_size = 32\n",
        "\n",
        "# data augmentation and normalization\n",
        "transform_train = transforms.Compose([\n",
        "                    transforms.RandomCrop(32, padding=4),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# download dataset\n",
        "train_and_val_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='dataset/',\n",
        "    train=True,\n",
        "    transform=transform_train,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='dataset/',\n",
        "    train=False,\n",
        "    transform=transform_test,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# split train and validation dataset\n",
        "train_size = int((1 - validation_split) * len(train_and_val_dataset))\n",
        "val_size = len(train_and_val_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_and_val_dataset, [train_size, val_size])\n",
        "\n",
        "# create dataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_num = len(test_dataset)\n",
        "test_steps = len(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz3sXl-pwdT9"
      },
      "source": [
        "## Create teacher and student models\n",
        "### Define BottleNeck for ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.245043Z",
          "iopub.status.busy": "2025-09-15T17:21:02.244775Z",
          "iopub.status.idle": "2025-09-15T17:21:02.252293Z",
          "shell.execute_reply": "2025-09-15T17:21:02.251546Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.245018Z"
        },
        "id": "xNQHKkcVwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIZdxOh-wdT-"
      },
      "source": [
        "### Define Resifual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.253296Z",
          "iopub.status.busy": "2025-09-15T17:21:02.253067Z",
          "iopub.status.idle": "2025-09-15T17:21:02.277396Z",
          "shell.execute_reply": "2025-09-15T17:21:02.276882Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.253273Z"
        },
        "id": "wkJimDp7wdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKwQR8oKwdT-"
      },
      "source": [
        "### Define ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.278332Z",
          "iopub.status.busy": "2025-09-15T17:21:02.278077Z",
          "iopub.status.idle": "2025-09-15T17:21:02.301112Z",
          "shell.execute_reply": "2025-09-15T17:21:02.300587Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.278307Z"
        },
        "id": "neQ5KljZwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, blocks_num, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channel = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
        "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "    def _make_layer(self, block, channel, block_num, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n",
        "        self.in_channel = channel * block.expansion\n",
        "\n",
        "        for _ in range(1, block_num):\n",
        "            layers.append(block(self.in_channel, channel))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Finish the forward pass and return the output layer as well as hidden features.\n",
        "        # 2. The output layer and hidden features will be used later for distilling.\n",
        "        # 3. You can refer to the ResNet structure illustration to finish it.\n",
        "        ## stem\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        ## extract features from each stage\n",
        "        feature1 = self.layer1(x)\n",
        "        feature2 = self.layer2(feature1)\n",
        "        feature3 = self.layer3(feature2)\n",
        "        feature4 = self.layer4(feature3)\n",
        "\n",
        "        ## classification head\n",
        "        out = self.avgpool(feature4)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        ## return logits + hidden features for distillation\n",
        "        return out, [feature1, feature2, feature3, feature4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOy4lBgSwdT-"
      },
      "source": [
        "### Define ResNet50 and Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.302108Z",
          "iopub.status.busy": "2025-09-15T17:21:02.301868Z",
          "iopub.status.idle": "2025-09-15T17:21:02.321736Z",
          "shell.execute_reply": "2025-09-15T17:21:02.321258Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.302092Z"
        },
        "id": "WmkTpoYzwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def resnet18(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "def resnet50(num_classes=10):\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3], num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vzi6uxFwdT-"
      },
      "source": [
        "## Teacher Model (ResNet50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.322519Z",
          "iopub.status.busy": "2025-09-15T17:21:02.322350Z",
          "iopub.status.idle": "2025-09-15T17:21:04.197301Z",
          "shell.execute_reply": "2025-09-15T17:21:04.196547Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.322505Z"
        },
        "id": "1UaF4WGXwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Teacher = resnet50(num_classes=10)  # commment out this line if loading trained teacher model\n",
        "# Teacher = torch.load('Teacher.pt', weights_only=False)  # loading trained teacher model\n",
        "Teacher = Teacher.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dmwXM_WtwdT_",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ResNet                                   --\n",
              "├─Conv2d: 1-1                            1,728\n",
              "├─BatchNorm2d: 1-2                       128\n",
              "├─ReLU: 1-3                              --\n",
              "├─MaxPool2d: 1-4                         --\n",
              "├─Sequential: 1-5                        --\n",
              "│    └─BottleNeck: 2-1                   --\n",
              "│    │    └─Conv2d: 3-1                  4,096\n",
              "│    │    └─BatchNorm2d: 3-2             128\n",
              "│    │    └─Conv2d: 3-3                  36,864\n",
              "│    │    └─BatchNorm2d: 3-4             128\n",
              "│    │    └─Conv2d: 3-5                  16,384\n",
              "│    │    └─BatchNorm2d: 3-6             512\n",
              "│    │    └─ReLU: 3-7                    --\n",
              "│    │    └─Sequential: 3-8              16,896\n",
              "│    └─BottleNeck: 2-2                   --\n",
              "│    │    └─Conv2d: 3-9                  16,384\n",
              "│    │    └─BatchNorm2d: 3-10            128\n",
              "│    │    └─Conv2d: 3-11                 36,864\n",
              "│    │    └─BatchNorm2d: 3-12            128\n",
              "│    │    └─Conv2d: 3-13                 16,384\n",
              "│    │    └─BatchNorm2d: 3-14            512\n",
              "│    │    └─ReLU: 3-15                   --\n",
              "│    └─BottleNeck: 2-3                   --\n",
              "│    │    └─Conv2d: 3-16                 16,384\n",
              "│    │    └─BatchNorm2d: 3-17            128\n",
              "│    │    └─Conv2d: 3-18                 36,864\n",
              "│    │    └─BatchNorm2d: 3-19            128\n",
              "│    │    └─Conv2d: 3-20                 16,384\n",
              "│    │    └─BatchNorm2d: 3-21            512\n",
              "│    │    └─ReLU: 3-22                   --\n",
              "├─Sequential: 1-6                        --\n",
              "│    └─BottleNeck: 2-4                   --\n",
              "│    │    └─Conv2d: 3-23                 32,768\n",
              "│    │    └─BatchNorm2d: 3-24            256\n",
              "│    │    └─Conv2d: 3-25                 147,456\n",
              "│    │    └─BatchNorm2d: 3-26            256\n",
              "│    │    └─Conv2d: 3-27                 65,536\n",
              "│    │    └─BatchNorm2d: 3-28            1,024\n",
              "│    │    └─ReLU: 3-29                   --\n",
              "│    │    └─Sequential: 3-30             132,096\n",
              "│    └─BottleNeck: 2-5                   --\n",
              "│    │    └─Conv2d: 3-31                 65,536\n",
              "│    │    └─BatchNorm2d: 3-32            256\n",
              "│    │    └─Conv2d: 3-33                 147,456\n",
              "│    │    └─BatchNorm2d: 3-34            256\n",
              "│    │    └─Conv2d: 3-35                 65,536\n",
              "│    │    └─BatchNorm2d: 3-36            1,024\n",
              "│    │    └─ReLU: 3-37                   --\n",
              "│    └─BottleNeck: 2-6                   --\n",
              "│    │    └─Conv2d: 3-38                 65,536\n",
              "│    │    └─BatchNorm2d: 3-39            256\n",
              "│    │    └─Conv2d: 3-40                 147,456\n",
              "│    │    └─BatchNorm2d: 3-41            256\n",
              "│    │    └─Conv2d: 3-42                 65,536\n",
              "│    │    └─BatchNorm2d: 3-43            1,024\n",
              "│    │    └─ReLU: 3-44                   --\n",
              "│    └─BottleNeck: 2-7                   --\n",
              "│    │    └─Conv2d: 3-45                 65,536\n",
              "│    │    └─BatchNorm2d: 3-46            256\n",
              "│    │    └─Conv2d: 3-47                 147,456\n",
              "│    │    └─BatchNorm2d: 3-48            256\n",
              "│    │    └─Conv2d: 3-49                 65,536\n",
              "│    │    └─BatchNorm2d: 3-50            1,024\n",
              "│    │    └─ReLU: 3-51                   --\n",
              "├─Sequential: 1-7                        --\n",
              "│    └─BottleNeck: 2-8                   --\n",
              "│    │    └─Conv2d: 3-52                 131,072\n",
              "│    │    └─BatchNorm2d: 3-53            512\n",
              "│    │    └─Conv2d: 3-54                 589,824\n",
              "│    │    └─BatchNorm2d: 3-55            512\n",
              "│    │    └─Conv2d: 3-56                 262,144\n",
              "│    │    └─BatchNorm2d: 3-57            2,048\n",
              "│    │    └─ReLU: 3-58                   --\n",
              "│    │    └─Sequential: 3-59             526,336\n",
              "│    └─BottleNeck: 2-9                   --\n",
              "│    │    └─Conv2d: 3-60                 262,144\n",
              "│    │    └─BatchNorm2d: 3-61            512\n",
              "│    │    └─Conv2d: 3-62                 589,824\n",
              "│    │    └─BatchNorm2d: 3-63            512\n",
              "│    │    └─Conv2d: 3-64                 262,144\n",
              "│    │    └─BatchNorm2d: 3-65            2,048\n",
              "│    │    └─ReLU: 3-66                   --\n",
              "│    └─BottleNeck: 2-10                  --\n",
              "│    │    └─Conv2d: 3-67                 262,144\n",
              "│    │    └─BatchNorm2d: 3-68            512\n",
              "│    │    └─Conv2d: 3-69                 589,824\n",
              "│    │    └─BatchNorm2d: 3-70            512\n",
              "│    │    └─Conv2d: 3-71                 262,144\n",
              "│    │    └─BatchNorm2d: 3-72            2,048\n",
              "│    │    └─ReLU: 3-73                   --\n",
              "│    └─BottleNeck: 2-11                  --\n",
              "│    │    └─Conv2d: 3-74                 262,144\n",
              "│    │    └─BatchNorm2d: 3-75            512\n",
              "│    │    └─Conv2d: 3-76                 589,824\n",
              "│    │    └─BatchNorm2d: 3-77            512\n",
              "│    │    └─Conv2d: 3-78                 262,144\n",
              "│    │    └─BatchNorm2d: 3-79            2,048\n",
              "│    │    └─ReLU: 3-80                   --\n",
              "│    └─BottleNeck: 2-12                  --\n",
              "│    │    └─Conv2d: 3-81                 262,144\n",
              "│    │    └─BatchNorm2d: 3-82            512\n",
              "│    │    └─Conv2d: 3-83                 589,824\n",
              "│    │    └─BatchNorm2d: 3-84            512\n",
              "│    │    └─Conv2d: 3-85                 262,144\n",
              "│    │    └─BatchNorm2d: 3-86            2,048\n",
              "│    │    └─ReLU: 3-87                   --\n",
              "│    └─BottleNeck: 2-13                  --\n",
              "│    │    └─Conv2d: 3-88                 262,144\n",
              "│    │    └─BatchNorm2d: 3-89            512\n",
              "│    │    └─Conv2d: 3-90                 589,824\n",
              "│    │    └─BatchNorm2d: 3-91            512\n",
              "│    │    └─Conv2d: 3-92                 262,144\n",
              "│    │    └─BatchNorm2d: 3-93            2,048\n",
              "│    │    └─ReLU: 3-94                   --\n",
              "├─Sequential: 1-8                        --\n",
              "│    └─BottleNeck: 2-14                  --\n",
              "│    │    └─Conv2d: 3-95                 524,288\n",
              "│    │    └─BatchNorm2d: 3-96            1,024\n",
              "│    │    └─Conv2d: 3-97                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-98            1,024\n",
              "│    │    └─Conv2d: 3-99                 1,048,576\n",
              "│    │    └─BatchNorm2d: 3-100           4,096\n",
              "│    │    └─ReLU: 3-101                  --\n",
              "│    │    └─Sequential: 3-102            2,101,248\n",
              "│    └─BottleNeck: 2-15                  --\n",
              "│    │    └─Conv2d: 3-103                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-104           1,024\n",
              "│    │    └─Conv2d: 3-105                2,359,296\n",
              "│    │    └─BatchNorm2d: 3-106           1,024\n",
              "│    │    └─Conv2d: 3-107                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-108           4,096\n",
              "│    │    └─ReLU: 3-109                  --\n",
              "│    └─BottleNeck: 2-16                  --\n",
              "│    │    └─Conv2d: 3-110                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-111           1,024\n",
              "│    │    └─Conv2d: 3-112                2,359,296\n",
              "│    │    └─BatchNorm2d: 3-113           1,024\n",
              "│    │    └─Conv2d: 3-114                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-115           4,096\n",
              "│    │    └─ReLU: 3-116                  --\n",
              "├─AdaptiveAvgPool2d: 1-9                 --\n",
              "├─Linear: 1-10                           20,490\n",
              "=================================================================\n",
              "Total params: 23,520,842\n",
              "Trainable params: 23,520,842\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(Teacher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ4wlBakwdT_"
      },
      "source": [
        "## Student Model (ResNet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.213935Z",
          "iopub.status.busy": "2025-09-15T17:21:04.213631Z",
          "iopub.status.idle": "2025-09-15T17:21:04.400068Z",
          "shell.execute_reply": "2025-09-15T17:21:04.399483Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.213911Z"
        },
        "id": "QsBS9LxPwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Student = resnet18(num_classes=10)  # commment out this line if loading trained student model\n",
        "# Student = torch.load('Student.pt', weights_only=False)  # loading trained student model\n",
        "Student = Student.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OJ8nTtDswdT_",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ResNet                                   --\n",
              "├─Conv2d: 1-1                            1,728\n",
              "├─BatchNorm2d: 1-2                       128\n",
              "├─ReLU: 1-3                              --\n",
              "├─MaxPool2d: 1-4                         --\n",
              "├─Sequential: 1-5                        --\n",
              "│    └─BasicBlock: 2-1                   --\n",
              "│    │    └─Conv2d: 3-1                  36,864\n",
              "│    │    └─BatchNorm2d: 3-2             128\n",
              "│    │    └─ReLU: 3-3                    --\n",
              "│    │    └─Conv2d: 3-4                  36,864\n",
              "│    │    └─BatchNorm2d: 3-5             128\n",
              "│    └─BasicBlock: 2-2                   --\n",
              "│    │    └─Conv2d: 3-6                  36,864\n",
              "│    │    └─BatchNorm2d: 3-7             128\n",
              "│    │    └─ReLU: 3-8                    --\n",
              "│    │    └─Conv2d: 3-9                  36,864\n",
              "│    │    └─BatchNorm2d: 3-10            128\n",
              "├─Sequential: 1-6                        --\n",
              "│    └─BasicBlock: 2-3                   --\n",
              "│    │    └─Conv2d: 3-11                 73,728\n",
              "│    │    └─BatchNorm2d: 3-12            256\n",
              "│    │    └─ReLU: 3-13                   --\n",
              "│    │    └─Conv2d: 3-14                 147,456\n",
              "│    │    └─BatchNorm2d: 3-15            256\n",
              "│    │    └─Sequential: 3-16             8,448\n",
              "│    └─BasicBlock: 2-4                   --\n",
              "│    │    └─Conv2d: 3-17                 147,456\n",
              "│    │    └─BatchNorm2d: 3-18            256\n",
              "│    │    └─ReLU: 3-19                   --\n",
              "│    │    └─Conv2d: 3-20                 147,456\n",
              "│    │    └─BatchNorm2d: 3-21            256\n",
              "├─Sequential: 1-7                        --\n",
              "│    └─BasicBlock: 2-5                   --\n",
              "│    │    └─Conv2d: 3-22                 294,912\n",
              "│    │    └─BatchNorm2d: 3-23            512\n",
              "│    │    └─ReLU: 3-24                   --\n",
              "│    │    └─Conv2d: 3-25                 589,824\n",
              "│    │    └─BatchNorm2d: 3-26            512\n",
              "│    │    └─Sequential: 3-27             33,280\n",
              "│    └─BasicBlock: 2-6                   --\n",
              "│    │    └─Conv2d: 3-28                 589,824\n",
              "│    │    └─BatchNorm2d: 3-29            512\n",
              "│    │    └─ReLU: 3-30                   --\n",
              "│    │    └─Conv2d: 3-31                 589,824\n",
              "│    │    └─BatchNorm2d: 3-32            512\n",
              "├─Sequential: 1-8                        --\n",
              "│    └─BasicBlock: 2-7                   --\n",
              "│    │    └─Conv2d: 3-33                 1,179,648\n",
              "│    │    └─BatchNorm2d: 3-34            1,024\n",
              "│    │    └─ReLU: 3-35                   --\n",
              "│    │    └─Conv2d: 3-36                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-37            1,024\n",
              "│    │    └─Sequential: 3-38             132,096\n",
              "│    └─BasicBlock: 2-8                   --\n",
              "│    │    └─Conv2d: 3-39                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-40            1,024\n",
              "│    │    └─ReLU: 3-41                   --\n",
              "│    │    └─Conv2d: 3-42                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-43            1,024\n",
              "├─AdaptiveAvgPool2d: 1-9                 --\n",
              "├─Linear: 1-10                           5,130\n",
              "=================================================================\n",
              "Total params: 11,173,962\n",
              "Trainable params: 11,173,962\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(Student)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF1RPSfrwdT_"
      },
      "source": [
        "## Define training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.411876Z",
          "iopub.status.busy": "2025-09-15T17:21:04.411049Z",
          "iopub.status.idle": "2025-09-15T17:21:04.429748Z",
          "shell.execute_reply": "2025-09-15T17:21:04.429207Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.411856Z"
        },
        "id": "sYihMy4lwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_from_scratch(model, train_loader, val_loader, epochs, learning_rate, device, model_name):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    # optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
        "\n",
        "    loss = []\n",
        "    train_error=[]\n",
        "    val_error = []\n",
        "    valdation_error = []\n",
        "    train_loss = []\n",
        "    valdation_loss = []\n",
        "    train_accuraacy = []\n",
        "    valdation_accuracy= []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc = 0.0\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "        V_correct = 0.\n",
        "        V_total = 0.\n",
        "\n",
        "        model.train()\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits, hidden = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pred = logits.data.max(1, keepdim=True)[1]\n",
        "            correct += np.sum(np.squeeze(pred.eq(labels.data.view_as(pred))).cpu().numpy())\n",
        "            total += images.size(0)\n",
        "            train_acc =  correct/total\n",
        "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "                outputs, hidden_outputs = model(val_images)\n",
        "                loss = criterion(outputs, val_labels)\n",
        "                valid_loss += loss.item() * val_images.size(0)\n",
        "                pred = outputs.data.max(1, keepdim=True)[1]\n",
        "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
        "                V_total += val_images.size(0)\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_error.append(train_loss)\n",
        "        valid_loss = valid_loss / len(val_loader.dataset)\n",
        "        val_error.append(valid_loss)\n",
        "        train_accuraacy.append( correct / total)\n",
        "        valdation_accuracy.append(V_correct / V_total)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
        "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
        "\n",
        "    torch.save(model, f'{model_name}.pt')\n",
        "    print(f'{model_name}.pt is saved')\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJihXOROwdT_"
      },
      "source": [
        "## Define testing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.431037Z",
          "iopub.status.busy": "2025-09-15T17:21:04.430762Z",
          "iopub.status.idle": "2025-09-15T17:21:04.452490Z",
          "shell.execute_reply": "2025-09-15T17:21:04.451992Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.431014Z"
        },
        "id": "IMcS6k_lwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader ,device, type=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    acc = 0.0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    if type == None:\n",
        "        model.eval()\n",
        "    elif type == 'distiller':\n",
        "        model.eval()\n",
        "        model.teacher.eval()\n",
        "        model.student.eval()\n",
        "    else:\n",
        "       raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_bar = tqdm(test_loader, file=sys.stdout)\n",
        "        for test_data in test_bar:\n",
        "            test_images, test_labels = test_data\n",
        "            test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "            if type == None:\n",
        "                outputs, features = model(test_images)\n",
        "                loss = criterion(outputs, test_labels)\n",
        "            elif type == 'distiller':\n",
        "                outputs, loss = model(test_images, test_labels)\n",
        "            else:\n",
        "                raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "            predict_y = torch.max(outputs, dim=1)[1]\n",
        "            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
        "            test_loss += loss.item()\n",
        "            test_bar.desc = \"test\"\n",
        "\n",
        "    test_accurate = acc / test_num\n",
        "    print('test_loss: %.3f  test_accuracy: %.3f' %(test_loss / test_steps, test_accurate * 100))\n",
        "    return test_loss / test_steps, test_accurate * 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOCKqaHXwdUA"
      },
      "source": [
        "## Train Teacher and Student model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model weights from ./Teacher.pt\n"
          ]
        }
      ],
      "source": [
        "best_teacher_path = './Teacher.pt'\n",
        "if os.path.exists(best_teacher_path):\n",
        "    Teacher = torch.load(best_teacher_path, weights_only=False)\n",
        "    print(f\"Loaded model weights from {best_teacher_path}\")\n",
        "else:\n",
        "    print(\"No saved model found, starting from scratch.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.453428Z",
          "iopub.status.busy": "2025-09-15T17:21:04.453203Z",
          "iopub.status.idle": "2025-09-15T17:21:04.473303Z",
          "shell.execute_reply": "2025-09-15T17:21:04.472761Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.453399Z"
        },
        "id": "MhWE8HSbwdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.46it/s]\n",
            "valid epoch[1/10]: 100%|██████████| 157/157 [00:01<00:00, 129.41it/s]\n",
            "\tTraining Loss: 0.072227 \tValidation Loss: 0.454244\n",
            "\tTrain Accuracy: 97.482d% (43867/45000)\tValdation Accuracy: 88.940d% (4447/5000) \n",
            "train epoch[2/10]: 100%|██████████| 1407/1407 [00:25<00:00, 55.84it/s]\n",
            "valid epoch[2/10]: 100%|██████████| 157/157 [00:01<00:00, 130.54it/s]\n",
            "\tTraining Loss: 0.072908 \tValidation Loss: 0.413532\n",
            "\tTrain Accuracy: 97.449d% (43852/45000)\tValdation Accuracy: 89.420d% (4471/5000) \n",
            "train epoch[3/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.41it/s]\n",
            "valid epoch[3/10]: 100%|██████████| 157/157 [00:01<00:00, 132.15it/s]\n",
            "\tTraining Loss: 0.071984 \tValidation Loss: 0.417559\n",
            "\tTrain Accuracy: 97.502d% (43876/45000)\tValdation Accuracy: 89.380d% (4469/5000) \n",
            "train epoch[4/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.51it/s]\n",
            "valid epoch[4/10]: 100%|██████████| 157/157 [00:01<00:00, 129.23it/s]\n",
            "\tTraining Loss: 0.070826 \tValidation Loss: 0.469942\n",
            "\tTrain Accuracy: 97.444d% (43850/45000)\tValdation Accuracy: 89.020d% (4451/5000) \n",
            "train epoch[5/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.22it/s]\n",
            "valid epoch[5/10]: 100%|██████████| 157/157 [00:01<00:00, 131.62it/s]\n",
            "\tTraining Loss: 0.072482 \tValidation Loss: 0.401858\n",
            "\tTrain Accuracy: 97.460d% (43857/45000)\tValdation Accuracy: 89.140d% (4457/5000) \n",
            "train epoch[6/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.13it/s]\n",
            "valid epoch[6/10]: 100%|██████████| 157/157 [00:01<00:00, 131.95it/s]\n",
            "\tTraining Loss: 0.071766 \tValidation Loss: 0.408555\n",
            "\tTrain Accuracy: 97.480d% (43866/45000)\tValdation Accuracy: 89.500d% (4475/5000) \n",
            "train epoch[7/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.32it/s]\n",
            "valid epoch[7/10]: 100%|██████████| 157/157 [00:01<00:00, 130.08it/s]\n",
            "\tTraining Loss: 0.072456 \tValidation Loss: 0.405747\n",
            "\tTrain Accuracy: 97.429d% (43843/45000)\tValdation Accuracy: 89.940d% (4497/5000) \n",
            "train epoch[8/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.69it/s]\n",
            "valid epoch[8/10]: 100%|██████████| 157/157 [00:01<00:00, 131.21it/s]\n",
            "\tTraining Loss: 0.070754 \tValidation Loss: 0.397476\n",
            "\tTrain Accuracy: 97.507d% (43878/45000)\tValdation Accuracy: 89.800d% (4490/5000) \n",
            "train epoch[9/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.56it/s]\n",
            "valid epoch[9/10]: 100%|██████████| 157/157 [00:01<00:00, 132.58it/s]\n",
            "\tTraining Loss: 0.071045 \tValidation Loss: 0.427412\n",
            "\tTrain Accuracy: 97.593d% (43917/45000)\tValdation Accuracy: 89.360d% (4468/5000) \n",
            "train epoch[10/10]: 100%|██████████| 1407/1407 [00:26<00:00, 52.15it/s]\n",
            "valid epoch[10/10]: 100%|██████████| 157/157 [00:01<00:00, 129.81it/s]\n",
            "\tTraining Loss: 0.073155 \tValidation Loss: 0.390497\n",
            "\tTrain Accuracy: 97.418d% (43838/45000)\tValdation Accuracy: 89.880d% (4494/5000) \n",
            "Teacher.pt is saved\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "train_from_scratch(Teacher, train_loader, val_loader, epochs=10 , learning_rate=0.00001 , device=device, model_name=\"Teacher\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.474123Z",
          "iopub.status.busy": "2025-09-15T17:21:04.473894Z",
          "iopub.status.idle": "2025-09-15T17:21:17.055237Z",
          "shell.execute_reply": "2025-09-15T17:21:17.054314Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.474108Z"
        },
        "id": "_PWsWuLqwdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 313/313 [00:02<00:00, 113.42it/s]\n",
            "test_loss: 0.384  test_accuracy: 90.340\n"
          ]
        }
      ],
      "source": [
        "T_loss, T_accuracy = test(Teacher, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No saved model found, starting from scratch.\n"
          ]
        }
      ],
      "source": [
        "best_student_path = './Student.pt'\n",
        "if os.path.exists(best_student_path):\n",
        "    Student = torch.load(best_student_path, weights_only=False)\n",
        "    print(f\"Loaded model weights from {best_student_path}\")\n",
        "else:\n",
        "    print(\"No saved model found, starting from scratch.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "L43plN89wdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/10]: 100%|██████████| 1407/1407 [00:14<00:00, 97.71it/s] \n",
            "valid epoch[1/10]: 100%|██████████| 157/157 [00:00<00:00, 205.16it/s]\n",
            "\tTraining Loss: 1.373968 \tValidation Loss: 1.254976\n",
            "\tTrain Accuracy: 50.191d% (22586/45000)\tValdation Accuracy: 54.100d% (2705/5000) \n",
            "train epoch[2/10]: 100%|██████████| 1407/1407 [00:11<00:00, 120.24it/s]\n",
            "valid epoch[2/10]: 100%|██████████| 157/157 [00:00<00:00, 208.07it/s]\n",
            "\tTraining Loss: 1.169915 \tValidation Loss: 1.101051\n",
            "\tTrain Accuracy: 58.033d% (26115/45000)\tValdation Accuracy: 60.240d% (3012/5000) \n",
            "train epoch[3/10]: 100%|██████████| 1407/1407 [00:11<00:00, 120.29it/s]\n",
            "valid epoch[3/10]: 100%|██████████| 157/157 [00:00<00:00, 206.57it/s]\n",
            "\tTraining Loss: 1.039268 \tValidation Loss: 0.974650\n",
            "\tTrain Accuracy: 63.044d% (28370/45000)\tValdation Accuracy: 65.840d% (3292/5000) \n",
            "train epoch[4/10]: 100%|██████████| 1407/1407 [00:11<00:00, 119.72it/s]\n",
            "valid epoch[4/10]: 100%|██████████| 157/157 [00:00<00:00, 207.24it/s]\n",
            "\tTraining Loss: 0.942961 \tValidation Loss: 0.907067\n",
            "\tTrain Accuracy: 66.653d% (29994/45000)\tValdation Accuracy: 67.820d% (3391/5000) \n",
            "train epoch[5/10]: 100%|██████████| 1407/1407 [00:11<00:00, 120.43it/s]\n",
            "valid epoch[5/10]: 100%|██████████| 157/157 [00:00<00:00, 208.89it/s]\n",
            "\tTraining Loss: 0.860778 \tValidation Loss: 0.842824\n",
            "\tTrain Accuracy: 69.318d% (31193/45000)\tValdation Accuracy: 70.760d% (3538/5000) \n",
            "train epoch[6/10]: 100%|██████████| 1407/1407 [00:11<00:00, 119.69it/s]\n",
            "valid epoch[6/10]: 100%|██████████| 157/157 [00:00<00:00, 208.25it/s]\n",
            "\tTraining Loss: 0.798361 \tValidation Loss: 0.837960\n",
            "\tTrain Accuracy: 72.004d% (32402/45000)\tValdation Accuracy: 70.720d% (3536/5000) \n",
            "train epoch[7/10]: 100%|██████████| 1407/1407 [00:11<00:00, 118.78it/s]\n",
            "valid epoch[7/10]: 100%|██████████| 157/157 [00:00<00:00, 206.45it/s]\n",
            "\tTraining Loss: 0.748254 \tValidation Loss: 0.764705\n",
            "\tTrain Accuracy: 73.544d% (33095/45000)\tValdation Accuracy: 73.580d% (3679/5000) \n",
            "train epoch[8/10]: 100%|██████████| 1407/1407 [00:11<00:00, 119.89it/s]\n",
            "valid epoch[8/10]: 100%|██████████| 157/157 [00:00<00:00, 209.25it/s]\n",
            "\tTraining Loss: 0.705477 \tValidation Loss: 0.736505\n",
            "\tTrain Accuracy: 75.353d% (33909/45000)\tValdation Accuracy: 74.220d% (3711/5000) \n",
            "train epoch[9/10]: 100%|██████████| 1407/1407 [00:11<00:00, 120.04it/s]\n",
            "valid epoch[9/10]: 100%|██████████| 157/157 [00:00<00:00, 202.77it/s]\n",
            "\tTraining Loss: 0.668957 \tValidation Loss: 0.700267\n",
            "\tTrain Accuracy: 76.453d% (34404/45000)\tValdation Accuracy: 76.420d% (3821/5000) \n",
            "train epoch[10/10]: 100%|██████████| 1407/1407 [00:11<00:00, 118.34it/s]\n",
            "valid epoch[10/10]: 100%|██████████| 157/157 [00:00<00:00, 202.59it/s]\n",
            "\tTraining Loss: 0.637630 \tValidation Loss: 0.652337\n",
            "\tTrain Accuracy: 77.704d% (34967/45000)\tValdation Accuracy: 77.540d% (3877/5000) \n",
            "Student.pt is saved\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "train_from_scratch(Student, train_loader, val_loader, epochs= 10, learning_rate= 0.001, device=device, model_name=\"Student\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:33.367646Z",
          "iopub.status.busy": "2025-09-15T17:29:33.367451Z",
          "iopub.status.idle": "2025-09-15T17:29:37.666896Z",
          "shell.execute_reply": "2025-09-15T17:29:37.666154Z",
          "shell.execute_reply.started": "2025-09-15T17:29:33.367631Z"
        },
        "id": "HJRhHt-qwdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 313/313 [00:01<00:00, 282.08it/s]\n",
            "test_loss: 0.616  test_accuracy: 79.310\n"
          ]
        }
      ],
      "source": [
        "S_loss, S_accuracy = test(Student, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmoN20JuwdUA"
      },
      "source": [
        "## Define distillation\n",
        "\n",
        "### Define the loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.668077Z",
          "iopub.status.busy": "2025-09-15T17:29:37.667767Z",
          "iopub.status.idle": "2025-09-15T17:29:37.672753Z",
          "shell.execute_reply": "2025-09-15T17:29:37.672224Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.668052Z"
        },
        "id": "2Jjd5o-KwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Finish the loss function for response-based distillation.\n",
        "def loss_re(student_logits, teacher_logits, targets):\n",
        "    T = 4 # Set temperature parameter\n",
        "    alpha = 0.5 # Set weighting parameter\n",
        "\n",
        "    ## Implement loss calculation\n",
        "    # ---- 1. Hard Loss ----\n",
        "    # typical cross entropy loss for student\n",
        "    hard_loss = F.cross_entropy(student_logits, targets)\n",
        "\n",
        "    # ---- 2. Soft Loss (Distillation Loss) ----\n",
        "    # Student soft predictions\n",
        "    student_soft = F.log_softmax(student_logits / T, dim=1)  # log Q_S\n",
        "\n",
        "    # Teacher soft predictions\n",
        "    teacher_soft = F.softmax(teacher_logits / T, dim=1)      # Q_T\n",
        "\n",
        "    # KL divergence: KL(Q_T || Q_S)\n",
        "    # In PyTorch: KLDivLoss expects log-prob input + prob target\n",
        "    soft_loss = F.kl_div(student_soft, teacher_soft, reduction='batchmean')\n",
        "\n",
        "    # ---- 3. Combine ----\n",
        "    loss = (1 - alpha) * hard_loss + (alpha * (T ** 2)) * soft_loss\n",
        "    \n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.692627Z",
          "iopub.status.busy": "2025-09-15T17:29:37.692345Z",
          "iopub.status.idle": "2025-09-15T17:29:37.712250Z",
          "shell.execute_reply": "2025-09-15T17:29:37.711759Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.692603Z"
        },
        "id": "otjdqnDFwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Finish the loss function for feature-based distillation.\n",
        "def loss_fe(student_features, teacher_features, connectors, student_logits, labels):\n",
        "    index = 1\n",
        "    alpha = 0.1\n",
        "    # Implement loss calculation whatever you prefer\n",
        "    # 1. Detach teacher feature (teacher is fixed)\n",
        "    t = teacher_features[index].detach()\n",
        "\n",
        "    # 2. Align student feature channels to teacher channels\n",
        "    #    connector: student C_s → teacher C_t\n",
        "    s_aligned = connectors[index](student_features[index])\n",
        "\n",
        "    # 3. Compute L2 loss\n",
        "    loss_f = F.mse_loss(s_aligned, t)\n",
        "    \n",
        "    # 4. Compute CE loss if logits and labels are provided\n",
        "    if student_logits is not None and labels is not None:\n",
        "        ce_loss = nn.CrossEntropyLoss()\n",
        "        loss_ce = ce_loss(student_logits, labels)\n",
        "    else:\n",
        "        loss_ce = 0.0\n",
        "\n",
        "    # 5. Combine feature loss and CE loss\n",
        "    loss = alpha * loss_f + (1 - alpha) * loss_ce\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhIgoti0wdUA"
      },
      "source": [
        "### Define Distillation Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.713139Z",
          "iopub.status.busy": "2025-09-15T17:29:37.712911Z",
          "iopub.status.idle": "2025-09-15T17:29:37.738648Z",
          "shell.execute_reply": "2025-09-15T17:29:37.738135Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.713114Z"
        },
        "id": "lPkIXEXPwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Distiller(nn.Module):\n",
        "    def __init__(self, teacher, student, type):\n",
        "        super(Distiller, self).__init__()\n",
        "\n",
        "        # 1. Finish the __init__ method.\n",
        "        self.teacher = teacher.eval()       # teacher fixed\n",
        "        self.student = student              # student trainable\n",
        "        self.type = type                    # 'response' or 'feature'\n",
        "\n",
        "        # ---------------------------\n",
        "        #  Connector layers for FKD\n",
        "        # ---------------------------\n",
        "        if type == 'feature':\n",
        "            self.connectors = nn.ModuleList([\n",
        "                nn.Conv2d(64, 256, 1),\n",
        "                nn.Conv2d(128, 512, 1),\n",
        "                nn.Conv2d(256, 1024, 1),\n",
        "                nn.Conv2d(512, 2048, 1),\n",
        "            ]).to(device)\n",
        "        else:\n",
        "            self.connectors = None\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        # 2. Finish the forward pass.\n",
        "        with torch.no_grad():\n",
        "            teacher_logits, teacher_features = self.teacher(x)\n",
        "\n",
        "        student_logits, student_features = self.student(x)\n",
        "\n",
        "        if self.type == 'response':\n",
        "            loss_distill = loss_re(student_logits, teacher_logits, target)\n",
        "        elif self.type == 'feature':\n",
        "            loss_distill = loss_fe(student_features, teacher_features, self.connectors, student_logits, target)\n",
        "        else:\n",
        "            raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "        return student_logits, loss_distill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQHEAueSwdUB"
      },
      "source": [
        "### Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.739676Z",
          "iopub.status.busy": "2025-09-15T17:29:37.739468Z",
          "iopub.status.idle": "2025-09-15T17:29:37.757328Z",
          "shell.execute_reply": "2025-09-15T17:29:37.756798Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.739661Z"
        },
        "id": "3sIn7IJXwdUB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_distillation(distiller, student, train_loader, val_loader, epochs, learning_rate, device):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    # define the parameter the optimizer used\n",
        "    optimizer = torch.optim.Adam(student.parameters(), lr=learning_rate)\n",
        "\n",
        "    loss = []\n",
        "    train_error=[]\n",
        "    val_error = []\n",
        "    valdation_error = []\n",
        "    train_loss = []\n",
        "    valdation_loss = []\n",
        "    train_accuraacy = []\n",
        "    valdation_accuracy= []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        distiller.train()\n",
        "        distiller.teacher.train()\n",
        "        distiller.student.train()\n",
        "\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc  = 0.0\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "        V_correct = 0.\n",
        "        V_total = 0.\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs, loss = distiller(images, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pred = outputs.data.max(1, keepdim=True)[1]\n",
        "            result = pred.eq(labels.data.view_as(pred))\n",
        "            result = np.squeeze(result.cpu().numpy())\n",
        "            correct += np.sum(result)\n",
        "            total += images.size(0)\n",
        "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        distiller.eval()\n",
        "        distiller.teacher.eval()\n",
        "        distiller.student.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "\n",
        "                val_images, val_labels = val_data\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "\n",
        "                outputs, loss = distiller(val_images, val_labels)\n",
        "\n",
        "                valid_loss += loss.item() * val_images.size(0)\n",
        "                pred = outputs.max(1, keepdim=True)[1]\n",
        "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
        "                V_total += val_images.size(0)\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_error.append(train_loss)\n",
        "        valid_loss = valid_loss / len(val_loader.dataset)\n",
        "        val_error.append(valid_loss)\n",
        "        train_accuraacy.append( correct / total)\n",
        "        valdation_accuracy.append(V_correct / V_total)\n",
        "\n",
        "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
        "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
        "\n",
        "    print('Finished Distilling')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At2fwU4LwdUB"
      },
      "source": [
        "## Response-based distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "WRN7odFawdUB",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/10]: 100%|██████████| 1407/1407 [00:30<00:00, 46.84it/s]\n",
            "valid epoch[1/10]: 100%|██████████| 157/157 [00:02<00:00, 77.79it/s]\n",
            "\tTraining Loss: 6.805971 \tValidation Loss: 5.063555\n",
            "\tTrain Accuracy: 48.358d% (21761/45000)\tValdation Accuracy: 58.020d% (2901/5000) \n",
            "train epoch[2/10]: 100%|██████████| 1407/1407 [00:29<00:00, 46.99it/s]\n",
            "valid epoch[2/10]: 100%|██████████| 157/157 [00:02<00:00, 78.49it/s]\n",
            "\tTraining Loss: 4.168979 \tValidation Loss: 3.376985\n",
            "\tTrain Accuracy: 65.836d% (29626/45000)\tValdation Accuracy: 69.220d% (3461/5000) \n",
            "train epoch[3/10]: 100%|██████████| 1407/1407 [00:30<00:00, 46.73it/s]\n",
            "valid epoch[3/10]: 100%|██████████| 157/157 [00:02<00:00, 78.46it/s]\n",
            "\tTraining Loss: 2.998611 \tValidation Loss: 2.589981\n",
            "\tTrain Accuracy: 73.842d% (33229/45000)\tValdation Accuracy: 73.660d% (3683/5000) \n",
            "train epoch[4/10]: 100%|██████████| 1407/1407 [00:30<00:00, 46.84it/s]\n",
            "valid epoch[4/10]: 100%|██████████| 157/157 [00:02<00:00, 76.67it/s]\n",
            "\tTraining Loss: 2.322870 \tValidation Loss: 2.014109\n",
            "\tTrain Accuracy: 78.142d% (35164/45000)\tValdation Accuracy: 79.900d% (3995/5000) \n",
            "train epoch[5/10]: 100%|██████████| 1407/1407 [00:27<00:00, 50.81it/s]\n",
            "valid epoch[5/10]: 100%|██████████| 157/157 [00:01<00:00, 81.30it/s]\n",
            "\tTraining Loss: 1.932411 \tValidation Loss: 1.716663\n",
            "\tTrain Accuracy: 80.896d% (36403/45000)\tValdation Accuracy: 80.640d% (4032/5000) \n",
            "train epoch[6/10]: 100%|██████████| 1407/1407 [00:27<00:00, 50.35it/s]\n",
            "valid epoch[6/10]: 100%|██████████| 157/157 [00:01<00:00, 82.86it/s]\n",
            "\tTraining Loss: 1.682955 \tValidation Loss: 1.476639\n",
            "\tTrain Accuracy: 83.031d% (37364/45000)\tValdation Accuracy: 82.440d% (4122/5000) \n",
            "train epoch[7/10]: 100%|██████████| 1407/1407 [00:27<00:00, 50.61it/s]\n",
            "valid epoch[7/10]: 100%|██████████| 157/157 [00:02<00:00, 77.60it/s]\n",
            "\tTraining Loss: 1.480156 \tValidation Loss: 1.457252\n",
            "\tTrain Accuracy: 84.211d% (37895/45000)\tValdation Accuracy: 83.800d% (4190/5000) \n",
            "train epoch[8/10]: 100%|██████████| 1407/1407 [00:30<00:00, 46.51it/s]\n",
            "valid epoch[8/10]: 100%|██████████| 157/157 [00:01<00:00, 78.73it/s]\n",
            "\tTraining Loss: 1.307209 \tValidation Loss: 1.458515\n",
            "\tTrain Accuracy: 85.898d% (38654/45000)\tValdation Accuracy: 83.320d% (4166/5000) \n",
            "train epoch[9/10]: 100%|██████████| 1407/1407 [00:29<00:00, 48.37it/s]\n",
            "valid epoch[9/10]: 100%|██████████| 157/157 [00:01<00:00, 78.59it/s]\n",
            "\tTraining Loss: 1.212663 \tValidation Loss: 1.342431\n",
            "\tTrain Accuracy: 86.698d% (39014/45000)\tValdation Accuracy: 83.900d% (4195/5000) \n",
            "train epoch[10/10]: 100%|██████████| 1407/1407 [00:29<00:00, 47.39it/s]\n",
            "valid epoch[10/10]: 100%|██████████| 157/157 [00:01<00:00, 89.15it/s]\n",
            "\tTraining Loss: 1.104953 \tValidation Loss: 1.137624\n",
            "\tTrain Accuracy: 87.769d% (39496/45000)\tValdation Accuracy: 86.220d% (4311/5000) \n",
            "Finished Distilling\n"
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "Student_re = resnet18(num_classes=10)\n",
        "Student_re = Student_re.to(device)\n",
        "distiller_re = Distiller(Teacher, Student_re, type='response')\n",
        "train_distillation(distiller_re, Student_re, train_loader, val_loader, epochs= 10, learning_rate= 0.001, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:46:23.908450Z",
          "iopub.status.busy": "2025-09-15T17:46:23.908252Z",
          "iopub.status.idle": "2025-09-15T17:46:37.767639Z",
          "shell.execute_reply": "2025-09-15T17:46:37.767023Z",
          "shell.execute_reply.started": "2025-09-15T17:46:23.908424Z"
        },
        "id": "uSwU5ooswdUO",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 313/313 [00:02<00:00, 120.98it/s]\n",
            "test_loss: 1.196  test_accuracy: 86.770\n"
          ]
        }
      ],
      "source": [
        "reS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdisKpMOwdUP"
      },
      "source": [
        "## Feature-based distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "kpshhQrNwdUP",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/10]: 100%|██████████| 1407/1407 [00:30<00:00, 46.04it/s]\n",
            "valid epoch[1/10]: 100%|██████████| 157/157 [00:02<00:00, 77.51it/s]\n",
            "\tTraining Loss: 1.564217 \tValidation Loss: 1.354475\n",
            "\tTrain Accuracy: 48.038d% (21617/45000)\tValdation Accuracy: 56.620d% (2831/5000) \n",
            "train epoch[2/10]: 100%|██████████| 1407/1407 [00:29<00:00, 47.09it/s]\n",
            "valid epoch[2/10]: 100%|██████████| 157/157 [00:01<00:00, 85.67it/s]\n",
            "\tTraining Loss: 1.190503 \tValidation Loss: 1.052575\n",
            "\tTrain Accuracy: 63.927d% (28767/45000)\tValdation Accuracy: 69.060d% (3453/5000) \n",
            "train epoch[3/10]: 100%|██████████| 1407/1407 [00:30<00:00, 46.26it/s]\n",
            "valid epoch[3/10]: 100%|██████████| 157/157 [00:01<00:00, 83.90it/s]\n",
            "\tTraining Loss: 1.013960 \tValidation Loss: 0.993026\n",
            "\tTrain Accuracy: 70.696d% (31813/45000)\tValdation Accuracy: 72.380d% (3619/5000) \n",
            "train epoch[4/10]: 100%|██████████| 1407/1407 [00:29<00:00, 47.55it/s]\n",
            "valid epoch[4/10]: 100%|██████████| 157/157 [00:02<00:00, 78.00it/s]\n",
            "\tTraining Loss: 0.901546 \tValidation Loss: 0.939881\n",
            "\tTrain Accuracy: 75.560d% (34002/45000)\tValdation Accuracy: 74.520d% (3726/5000) \n",
            "train epoch[5/10]: 100%|██████████| 1407/1407 [00:28<00:00, 49.83it/s]\n",
            "valid epoch[5/10]: 100%|██████████| 157/157 [00:01<00:00, 87.60it/s]\n",
            "\tTraining Loss: 0.829837 \tValidation Loss: 0.835263\n",
            "\tTrain Accuracy: 78.093d% (35142/45000)\tValdation Accuracy: 78.460d% (3923/5000) \n",
            "train epoch[6/10]: 100%|██████████| 1407/1407 [00:29<00:00, 46.97it/s]\n",
            "valid epoch[6/10]: 100%|██████████| 157/157 [00:02<00:00, 78.03it/s]\n",
            "\tTraining Loss: 0.777141 \tValidation Loss: 0.808055\n",
            "\tTrain Accuracy: 80.120d% (36054/45000)\tValdation Accuracy: 79.740d% (3987/5000) \n",
            "train epoch[7/10]: 100%|██████████| 1407/1407 [00:29<00:00, 47.89it/s]\n",
            "valid epoch[7/10]: 100%|██████████| 157/157 [00:02<00:00, 77.13it/s]\n",
            "\tTraining Loss: 0.734314 \tValidation Loss: 0.789371\n",
            "\tTrain Accuracy: 81.898d% (36854/45000)\tValdation Accuracy: 79.840d% (3992/5000) \n",
            "train epoch[8/10]: 100%|██████████| 1407/1407 [00:30<00:00, 46.13it/s]\n",
            "valid epoch[8/10]: 100%|██████████| 157/157 [00:02<00:00, 76.30it/s]\n",
            "\tTraining Loss: 0.694373 \tValidation Loss: 0.751937\n",
            "\tTrain Accuracy: 83.313d% (37491/45000)\tValdation Accuracy: 81.440d% (4072/5000) \n",
            "train epoch[9/10]: 100%|██████████| 1407/1407 [00:30<00:00, 46.30it/s]\n",
            "valid epoch[9/10]: 100%|██████████| 157/157 [00:02<00:00, 76.55it/s]\n",
            "\tTraining Loss: 0.663969 \tValidation Loss: 0.731747\n",
            "\tTrain Accuracy: 84.336d% (37951/45000)\tValdation Accuracy: 81.920d% (4096/5000) \n",
            "train epoch[10/10]: 100%|██████████| 1407/1407 [00:28<00:00, 48.91it/s]\n",
            "valid epoch[10/10]: 100%|██████████| 157/157 [00:02<00:00, 76.42it/s]\n",
            "\tTraining Loss: 0.634976 \tValidation Loss: 0.713305\n",
            "\tTrain Accuracy: 85.431d% (38444/45000)\tValdation Accuracy: 82.920d% (4146/5000) \n",
            "Finished Distilling\n"
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "Student_fe = resnet18(num_classes=10)\n",
        "Student_fe = Student_fe.to(device)\n",
        "distiller_fe = Distiller(Teacher, Student_fe, type='feature')\n",
        "train_distillation(distiller_fe, Student_fe, train_loader, val_loader, epochs= 10, learning_rate= 0.001, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T18:12:41.350107Z",
          "iopub.status.busy": "2025-09-15T18:12:41.349535Z",
          "iopub.status.idle": "2025-09-15T18:12:56.380748Z",
          "shell.execute_reply": "2025-09-15T18:12:56.380147Z",
          "shell.execute_reply.started": "2025-09-15T18:12:41.350082Z"
        },
        "id": "zM9-xs6SwdUP",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 313/313 [00:03<00:00, 99.93it/s] \n",
            "test_loss: 0.605  test_accuracy: 87.270\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ftS_loss, ftS_accuracy = test(distiller_fe, test_loader, type='distiller', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7OsAvhwdUP"
      },
      "source": [
        "## Result and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T18:12:56.382324Z",
          "iopub.status.busy": "2025-09-15T18:12:56.381931Z",
          "iopub.status.idle": "2025-09-15T18:12:56.387139Z",
          "shell.execute_reply": "2025-09-15T18:12:56.386278Z",
          "shell.execute_reply.started": "2025-09-15T18:12:56.382306Z"
        },
        "id": "nsK1wsDmwdUP",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher from scratch: loss = 0.38, accuracy = 90.34\n",
            "Student from scratch: loss = 0.62, accuracy = 79.31\n",
            "Response-based student: loss = 1.20, accuracy = 86.77\n",
            "Featured-based student: loss = 0.61, accuracy = 87.27\n"
          ]
        }
      ],
      "source": [
        "print(f'Teacher from scratch: loss = {T_loss:.2f}, accuracy = {T_accuracy:.2f}')\n",
        "print(f'Student from scratch: loss = {S_loss:.2f}, accuracy = {S_accuracy:.2f}')\n",
        "print(f'Response-based student: loss = {reS_loss:.2f}, accuracy = {reS_accuracy:.2f}')\n",
        "print(f'Featured-based student: loss = {ftS_loss:.2f}, accuracy = {ftS_accuracy:.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "isSourceIdPinned": true,
          "modelId": 450656,
          "modelInstanceId": 433802,
          "sourceId": 581181,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31090,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "EAI_Lab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
