{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1 Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zLblU_gpfrRQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from thop import profile\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV3P0XNCfuNZ",
        "outputId": "900de73e-3977-4c6f-e028-35bc491181ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLpt7FTrfvwN",
        "outputId": "f72722ce-bc15-4d03-f688-7000b3bf6bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.49139842 0.48215684 0.44652966] [0.24703267 0.24348429 0.26158786]\n",
            "[0.49139842 0.48215684 0.44652966] [0.24703267 0.24348429 0.26158786]\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean and std of dataset\n",
        "def get_mean_std(dataset, ratio=1):\n",
        "    # Get mean and std by sample ratio\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=int(len(dataset)*ratio), shuffle=True, num_workers=2)\n",
        "\n",
        "    data = next(iter(dataloader))[0]     # get the first iteration data\n",
        "    mean = np.mean(data.numpy(), axis=(0,2,3))\n",
        "    std = np.std(data.numpy(), axis=(0,2,3))\n",
        "    return mean, std\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_mean, train_std = get_mean_std(train_dataset)\n",
        "test_mean, test_std = train_mean, train_std\n",
        "print(train_mean, train_std)\n",
        "print(test_mean, test_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KUhAqjSNfxuY"
      },
      "outputs": [],
      "source": [
        "##### data augmentation & normalization #####\n",
        "transform_train = transforms.Compose([\n",
        "    # 同學實作部分：Add data augmentation here\n",
        "    transforms.RandomRotation(15,expand = True),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.5),\n",
        "    \n",
        "    transforms.ToTensor(), # Transform to tensor\n",
        "    transforms.Normalize(mean=train_mean, std=train_std), # Normalization\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=test_mean, std=test_std),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NltFsUEffz48",
        "outputId": "55e4c378-6e46-4b29-c39f-7025b0a3b73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image shape:  torch.Size([3, 224, 224])\n",
            "train length:  45000\n",
            "val length:  5000\n",
            "test length:  10000\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_ds = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "image, label = trainset[0]\n",
        "print(\"image shape: \", image.shape)\n",
        "\n",
        "# Split validation dataset\n",
        "torch.manual_seed(43)     # Ensure reproducibility\n",
        "val_size = 5000       # Take 5000 images as validation set\n",
        "train_size = len(trainset) - val_size\n",
        "train_ds, val_ds = random_split(trainset, [train_size, val_size])\n",
        "print(\"train length: \", len(train_ds))\n",
        "print(\"val length: \", len(val_ds))\n",
        "print(\"test length: \", len(test_ds))\n",
        "\n",
        "# Declare batch size\n",
        "# 學生實作部分：Set batch size\n",
        "BATCH_SIZE = 16\n",
        "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ph1fHTwff2Qq"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, expansion: int = 1, downsample: nn.Module = None,):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # 學生實作部分：Define the two convolutional layers and the shortcut connection\n",
        "        self.expansion = expansion\n",
        "        self.downsample = downsample\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels,\n",
        "            out_channels * self.expansion,\n",
        "            kernel_size=3,\n",
        "            padding=1,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 學生實作部分：Define the forward pass using convolutional layers and the shortcut connection\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(ResNet18, self).__init__()\n",
        "        # 學生實作部分：Define the ResNet-18 architecture using BasicBlock\n",
        "        layers = [2, 2, 2, 2]\n",
        "        self.expansion = 1\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=self.in_channels,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(BasicBlock, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(BasicBlock, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(BasicBlock, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * self.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        # 學生實作部分：Define make_layer function to create layers of blocks\n",
        "        downsample = None\n",
        "        if stride != 1:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    out_channels * self.expansion,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(self.in_channels, out_channels, stride, self.expansion, downsample)\n",
        "        )\n",
        "        self.in_channels = out_channels * self.expansion\n",
        "\n",
        "        for i in range(1, num_blocks):\n",
        "            layers.append(\n",
        "                block(self.in_channels, out_channels, expansion=self.expansion)\n",
        "            )\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 學生實作部分：Define the forward pass of ResNet-18\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        out = self.fc(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6-BvIaDNgGpc",
        "outputId": "c7b9f973-e201-4af5-a061-07f9293dfd5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,181,642\n",
            "Trainable params: 11,181,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.65\n",
            "Estimated Total Size (MB): 106.01\n",
            "----------------------------------------------------------------\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "FLOPs: 37.22 MFLOPs\n",
            "Params: 11.18 M\n"
          ]
        }
      ],
      "source": [
        "# Create SummaryWriter\n",
        "writer = SummaryWriter(\"./tensorboard\")\n",
        "\n",
        "model = ResNet18(num_classes=10)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "# Print model summary\n",
        "summary(model, (3, 224, 224))\n",
        "\n",
        "# Calculate FLOPs and Params\n",
        "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "flops, params = profile(model, inputs=(dummy_input, ))\n",
        "print(f\"FLOPs: {flops/1e6:.2f} MFLOPs\")\n",
        "print(f\"Params: {params/1e6:.2f} M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "collapsed": true,
        "id": "sW_kszMZD5vm",
        "outputId": "219de866-ad15-4b9a-8325-be166fc84ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running epoch: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2813 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
            "  0%|          | 0/2813 [00:07<?, ?it/s]    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 2264, in <module>\n",
            "    from torch import quantization as quantization  # usort: skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/quantization/__init__.py\", line 2, in <module>\n",
            "    from .fake_quantize import *  # noqa: F403\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/quantization/fake_quantize.py\", line 10, in <module>\n",
            "    from torch.ao.quantization.fake_quantize import (\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/ao/quantization/__init__.py\", line 12, in <module>\n",
            "    from .pt2e._numeric_debugger import (  # noqa: F401\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/ao/quantization/pt2e/_numeric_debugger.py\", line 9, in <module>\n",
            "    from torch.ao.quantization.pt2e.graph_utils import bfs_trace_with_node_process\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/ao/quantization/pt2e/graph_utils.py\", line 9, in <module>\n",
            "    from torch.export import ExportedProgram\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/export/__init__.py\", line 17, in <module>\n",
            "    from torch.fx.passes.infra.pass_base import PassResult\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/fx/passes/__init__.py\", line 1, in <module>\n",
            "    from . import (\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/fx/passes/graph_drawer.py\", line 14, in <module>\n",
            "    from torch.fx.passes.shape_prop import TensorMetadata\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/fx/passes/shape_prop.py\", line 11, in <module>\n",
            "    from torch._subclasses.meta_utils import is_sparse_any\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/_subclasses/__init__.py\", line 2, in <module>\n",
            "    from torch._subclasses.fake_tensor import (\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 30, in <module>\n",
            "    from torch._subclasses.meta_utils import (\n",
            "  File \"/Users/jackiempty/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/_subclasses/meta_utils.py\", line 599, in <module>\n",
            "    @dataclass(frozen=True)\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py\", line 1222, in wrap\n",
            "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py\", line 1078, in _process_class\n",
            "    for fn in _frozen_get_del_attr(cls, field_list, globals):\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py\", line 614, in _frozen_get_del_attr\n",
            "    _create_fn('__delattr__',\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/dataclasses.py\", line 433, in _create_fn\n",
            "    exec(txt, globals, ns)\n",
            "  File \"<string>\", line 0, in <module>\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m train_correct = \u001b[32m0\u001b[39m\n\u001b[32m     33\u001b[39m train_total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# move tensors to GPU if CUDA is available\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# clear the gradients of all optimized variables\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Git_repo/AISLab/EAI_Lab/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1172\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1165\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1171\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1172\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1174\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:288\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         f.write(fp.getbuffer())\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Setting parameter\n",
        "EPOCH = 10\n",
        "pre_epoch = 5\n",
        "lr = 0.0001\n",
        "\n",
        "# 同學可以根據自己需求調整optimizer, criterion與lr_scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "best_model_path = 'best_resnet18.pth'\n",
        "\n",
        "# Record training and validation metrics\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "best_val_acc = 0.0\n",
        "\n",
        "# Training and validation loop\n",
        "for epoch in range(pre_epoch, EPOCH):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # 學生實作部分：Complete the training and validation loop\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    print('running epoch: {}'.format(epoch))\n",
        "\n",
        "    # train the model\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    for data, target in tqdm(trainloader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        # update training Accuracy\n",
        "        train_total += target.size(0)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        train_correct += (predicted == target).sum().item()\n",
        "\n",
        "\n",
        "    # validate the model\n",
        "    model.eval()\n",
        "    valid_correct = 0\n",
        "    valid_total = 0\n",
        "    for data, target in tqdm(validloader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        target = target.long()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        # update validation Accuracy\n",
        "        valid_total += target.size(0)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        valid_correct += (predicted == target).sum().item()\n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(trainloader.dataset)\n",
        "    valid_loss = valid_loss/len(validloader.dataset)\n",
        "\n",
        "    train_acc = 100 * train_correct / train_total\n",
        "    val_acc = 100 * valid_correct / valid_total\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_losses.append(valid_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "    \n",
        "    \n",
        "    # 儲存最佳模型\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{EPOCH}] \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "          f\"Val Loss: {valid_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKJJVv3zGYHI",
        "outputId": "b1b35fdb-26ce-4693-fd32-b10598354590"
      },
      "outputs": [],
      "source": [
        "# Load the best model and evaluate on the test set\n",
        "model.eval()\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for test_inputs, test_labels in testloader:\n",
        "        test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
        "        test_outputs = model(test_inputs)\n",
        "        _, test_predicted = test_outputs.max(1)\n",
        "        test_total += test_labels.size(0)\n",
        "        test_correct += test_predicted.eq(test_labels).sum().item()\n",
        "test_accuracy = 100. * test_correct / test_total\n",
        "print(f\"Best Model Test Accuracy: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "SHm67TRfgI_P",
        "outputId": "e8c2762c-0729-441a-e1b3-b6410bf53c08"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_losses' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m     ax1.set_xlabel(\u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     26\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mplt_loss_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m plt_acc_all()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mplt_loss_all\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     18\u001b[39m ax1 = fig.add_subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     19\u001b[39m ax1.set_title(\u001b[33m'\u001b[39m\u001b[33mAll loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m ax1.plot(\u001b[43mtrain_losses\u001b[49m)\n\u001b[32m     22\u001b[39m ax1.plot(val_losses)\n\u001b[32m     24\u001b[39m ax1.legend([\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvalid_loss\u001b[39m\u001b[33m'\u001b[39m], loc=\u001b[33m'\u001b[39m\u001b[33mupper left\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'train_losses' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##### Plot loss & accuracy graph #####\n",
        "import matplotlib.pyplot as plt\n",
        "# 學生實作部分：Plot training and validation loss and accuracy curves\n",
        "def plt_acc_all():\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax1.set_title('All acc')\n",
        "\n",
        "    ax1.plot(train_accuracies)\n",
        "    ax1.plot(val_accuracies)\n",
        "\n",
        "    ax1.legend(['train_acc', 'valid_acc'], loc='upper left')\n",
        "    ax1.set_xlabel('epoch')\n",
        "    plt.show()\n",
        "\n",
        "def plt_loss_all():\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax1.set_title('All loss')\n",
        "\n",
        "    ax1.plot(train_losses)\n",
        "    ax1.plot(val_losses)\n",
        "\n",
        "    ax1.legend(['train_loss', 'valid_loss'], loc='upper left')\n",
        "    ax1.set_xlabel('epoch')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plt_loss_all()\n",
        "plt_acc_all()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
